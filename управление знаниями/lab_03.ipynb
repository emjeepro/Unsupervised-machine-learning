{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4zVgUKuEG9m"
      },
      "source": [
        "## Лаб.03\n",
        "\n",
        "### Применение полносвязной ИНС для решения задачи регрессии\n",
        "\n",
        "---\n",
        "\n",
        "#### Задание:\n",
        "Познакомиться с простейшими приемами применения ИНС для решения задачи регрессии. [Описание исходного набора данных California Housing Prices](https://www.kaggle.com/datasets/camnugent/california-housing-prices) (на английском языке).\n",
        "В наборе содержится информация о средней по кварталу стоимости домов в Калифорнии. Файл `CaliforniaHousingPrices.csv` содержит следующие столбцы:\n",
        "* longitude – долгота квартала,\n",
        "* latitude – широта квартала,\n",
        "* housing_median_age – медиана возраста домов в квартале,\n",
        "* total_rooms – общее количество комнат,\n",
        "* total_bedrooms – общее количество спален,\n",
        "* population – население квартала,\n",
        "* households – количество домохозяйств в квартале – групп людей, живущих вместе в одном доме (как правило, семьи).\n",
        "* median_income – медианный доход в квартале,\n",
        "* median_house_value – медианная по кварталу стоимость дома – целевой (прогнозируемый) признак.\n",
        "\n",
        "Необходимо построить и обучить полносвязную ИНС для прогнозирования медианной цены дома на основании указанных выше входных признаков.\n",
        "\n",
        "**Порядок выполнения работы:**\n",
        "1.\tИмпортируйте данные исходного набора. Для повышения скорости обработки данных в Colab можно подключить Google-диск, предварительно сохранив на нем необходимые файлы. Для подключения диска нужно использовать вертикальное меню слева (раздел Файлы, кнопка Подключить диск) – автоматически создается ячейка с кодом подключения, которую нужно запустить.\n",
        "2.\tВыведите фрагмент импортированного набора для контроля корректности передачи данных.\n",
        "3.\tРазделите набор данных на обучающую и тестовую выборку в соотношении 80/20. Можно использовать функцию `train_test_split()` из библиотеки  `sklearn`.\n",
        "4.\tСформируйте массивы правильных ответов y_train и y_test из обучающего и тестового наборов соответственно, а также массивы x_train и x_test, содержащие входные признаки объектов.<br><u>Указание</u>. Могут быть полезны методы `DataFrame.pop()`, который возвращает указанный столбец, одновременно удаляя его из исходной таблицы <br>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html <br>и `DataFrame.values()` <br>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html <br>Выведите тип (надо убедиться, что массивы) и размерность полученных объектов.\n",
        "5.\tВыполните масштабирование входных признаков обучающего и тестового набора. Рекомендуется метод стандартизации (лучше обрабатывает выбросы и аномалии).\n",
        "6.\tСоздайте модель полносвязной ИНС с двумя скрытыми и выходным слоем. На первом скрытом слое 64, на втором – 32 нейрона; функция активации на всех слоях ReLU.\n",
        "7.\tСкомпилируйте модель, задав метрику MAE, функцию потерь MSE и оптимизатор Nadam. Выведите информацию о полученной архитектуре ИНС и количестве обучаемых параметров. Сопоставьте с объемом обучающих данных, сделайте вывод.\n",
        "8.\tЗапустите процесс обучения сети с использованием проверочного набора (10% от обучающих данных) и выводом информации о процессе обучения. Установите 300 эпох обучения. Контролируйте значения метрики на обучающих и проверочных данных, убедитесь в отсутствии переобучения.\n",
        "9.\tВыполните оценку качества обученной модели на тестовых данных. Для ИНС с описанной выше архитектурой и параметрами обучения должно получиться значение около 45000 (может варьироваться в зависимости от способа разбиения исходного набора).\n",
        "10.\tИзменяя параметры архитектуры ИНС (в рамках RNN) и параметры обучения, постарайтесь добиться MAE<37000 на тестовых данных. Можно изменять:<br>• количество слоев ИНС;<br>• количество нейронов в скрытых слоях;<br>• функции активации;<br>• оптимизатор;<br>• размер подвыборок (батчей);<br>• количество эпох обучения.\n",
        "11.\tСохраните лучшую модель.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwQiUbmmKWBz"
      },
      "source": [
        "1.\tИмпортируйте данные исходного набора. Для повышения скорости обработки данных в Colab можно подключить Google-диск, предварительно сохранив на нем необходимые файлы. Для подключения диска нужно использовать вертикальное меню слева (раздел Файлы, кнопка Подключить диск) – автоматически создается ячейка с кодом подключения, которую нужно запустить."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5rQJiCOJpUQ"
      },
      "outputs": [],
      "source": [
        "# подключим библиотеки для анализа данных и выбора модели машинного обучения\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY1gaFIhLAbl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip4QKBwMLC35"
      },
      "outputs": [],
      "source": [
        "# добавим данные в датаафрейм\n",
        "\n",
        "# use this line if on Jupyter\n",
        "# data = pd.read_csv('CaliforniaHousingPrices.csv')\n",
        "\n",
        "# use this line if on Colab\n",
        "data = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/CaliforniaHousingPrices.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kR8HwDlFLtHt"
      },
      "source": [
        "---\n",
        "\n",
        "2.\tВыведите фрагмент импортированного набора для контроля корректности передачи данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KVDdrsT-Lar0",
        "outputId": "a4ab2793-45c7-4c61-cf05-9f16455f5ea8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-10609e91-0d04-476d-9dab-f36ecc67dc14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.30</td>\n",
              "      <td>37.92</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3943.0</td>\n",
              "      <td>605.0</td>\n",
              "      <td>1524.0</td>\n",
              "      <td>614.0</td>\n",
              "      <td>6.0677</td>\n",
              "      <td>321600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-121.80</td>\n",
              "      <td>37.27</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3301.0</td>\n",
              "      <td>593.0</td>\n",
              "      <td>2190.0</td>\n",
              "      <td>575.0</td>\n",
              "      <td>6.2230</td>\n",
              "      <td>260700.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-118.20</td>\n",
              "      <td>33.96</td>\n",
              "      <td>44.0</td>\n",
              "      <td>2144.0</td>\n",
              "      <td>477.0</td>\n",
              "      <td>1760.0</td>\n",
              "      <td>452.0</td>\n",
              "      <td>2.3221</td>\n",
              "      <td>161600.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-121.50</td>\n",
              "      <td>38.53</td>\n",
              "      <td>37.0</td>\n",
              "      <td>3642.0</td>\n",
              "      <td>684.0</td>\n",
              "      <td>1508.0</td>\n",
              "      <td>657.0</td>\n",
              "      <td>3.5231</td>\n",
              "      <td>114300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-121.58</td>\n",
              "      <td>39.15</td>\n",
              "      <td>34.0</td>\n",
              "      <td>1376.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>702.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>1.4946</td>\n",
              "      <td>55500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10609e91-0d04-476d-9dab-f36ecc67dc14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10609e91-0d04-476d-9dab-f36ecc67dc14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10609e91-0d04-476d-9dab-f36ecc67dc14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0    -122.30     37.92                32.0       3943.0           605.0   \n",
              "1    -121.80     37.27                10.0       3301.0           593.0   \n",
              "2    -118.20     33.96                44.0       2144.0           477.0   \n",
              "3    -121.50     38.53                37.0       3642.0           684.0   \n",
              "4    -121.58     39.15                34.0       1376.0           376.0   \n",
              "\n",
              "   population  households  median_income  median_house_value  \n",
              "0      1524.0       614.0         6.0677            321600.0  \n",
              "1      2190.0       575.0         6.2230            260700.0  \n",
              "2      1760.0       452.0         2.3221            161600.0  \n",
              "3      1508.0       657.0         3.5231            114300.0  \n",
              "4       702.0       317.0         1.4946             55500.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# выведем первые 5 строк таблицы\n",
        "\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFexAR-cL9Ru",
        "outputId": "f10e55ab-742d-4127-84b4-06b4b808fbaf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of        longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
              "0        -122.30     37.92                32.0       3943.0           605.0   \n",
              "1        -121.80     37.27                10.0       3301.0           593.0   \n",
              "2        -118.20     33.96                44.0       2144.0           477.0   \n",
              "3        -121.50     38.53                37.0       3642.0           684.0   \n",
              "4        -121.58     39.15                34.0       1376.0           376.0   \n",
              "...          ...       ...                 ...          ...             ...   \n",
              "16995    -121.23     37.92                28.0        590.0           129.0   \n",
              "16996    -119.79     36.85                11.0       2596.0           619.0   \n",
              "16997    -117.89     33.87                32.0       1569.0           422.0   \n",
              "16998    -121.33     38.62                19.0       1853.0           415.0   \n",
              "16999    -121.47     38.54                36.0       2099.0           510.0   \n",
              "\n",
              "       population  households  median_income  median_house_value  \n",
              "0          1524.0       614.0         6.0677            321600.0  \n",
              "1          2190.0       575.0         6.2230            260700.0  \n",
              "2          1760.0       452.0         2.3221            161600.0  \n",
              "3          1508.0       657.0         3.5231            114300.0  \n",
              "4           702.0       317.0         1.4946             55500.0  \n",
              "...           ...         ...            ...                 ...  \n",
              "16995       315.0        99.0         1.8958             85700.0  \n",
              "16996      1765.0       539.0         1.9511             54000.0  \n",
              "16997       835.0       386.0         3.0465            148900.0  \n",
              "16998       772.0       397.0         2.2574            135800.0  \n",
              "16999      1845.0       483.0         1.4138             52500.0  \n",
              "\n",
              "[17000 rows x 9 columns]>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# информация о наборе данных\n",
        "\n",
        "data.info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQYuCaF6L1qs"
      },
      "source": [
        "---\n",
        "\n",
        "3.\tРазделите набор данных на обучающую и тестовую выборку в соотношении 80/20. Можно использовать функцию `train_test_split()` из библиотеки  `sklearn`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQQcJIl4N8A-"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"median_house_value\"])\n",
        "y = np.array(data[\"median_house_value\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFCsIt_OL2wr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVV-vrznOu7L"
      },
      "source": [
        "---\n",
        "\n",
        "4.\tСформируйте массивы правильных ответов y_train и y_test из обучающего и тестового наборов соответственно, а также массивы x_train и x_test, содержащие входные признаки объектов.<br><u>Указание</u>. Могут быть полезны методы `DataFrame.pop()`, который возвращает указанный столбец, одновременно удаляя его из исходной таблицы <br>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pop.html <br>и `DataFrame.values()` <br>https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.values.html <br>Выведите тип (надо убедиться, что массивы) и размерность полученных объектов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RatWpsnGOwKS"
      },
      "outputs": [],
      "source": [
        "y_train = train_set['median_house_value'].copy()\n",
        "x_train = train_set.drop('median_house_value', axis=1).copy()\n",
        "\n",
        "y_test = test_set['median_house_value'].copy()\n",
        "x_test = test_set.drop('median_house_value', axis=1).copy()\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3WxafgzRcP4"
      },
      "source": [
        "---\n",
        "\n",
        "5.\tВыполните масштабирование входных признаков обучающего и тестового набора. Рекомендуется метод стандартизации (лучше обрабатывает выбросы и аномалии)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPT5FMo5Rds-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV5TtySASHD7"
      },
      "source": [
        "---\n",
        "\n",
        "6.\tСоздайте модель полносвязной ИНС с двумя скрытыми и выходным слоем. На первом скрытом слое 64, на втором – 32 нейрона; функция активации на всех слоях ReLU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ChgHuUSLKA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(8,)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4aayOnsSmQL"
      },
      "source": [
        "---\n",
        "\n",
        "7.\tСкомпилируйте модель, задав метрику MAE, функцию потерь MSE и оптимизатор Nadam. Выведите информацию о полученной архитектуре ИНС и количестве обучаемых параметров. Сопоставьте с объемом обучающих данных, сделайте вывод."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHoMNyg9Sv4q",
        "outputId": "04f191df-2f9f-4ee1-ce91-13d0a5b4f2f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                576       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,689\n",
            "Trainable params: 2,689\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='Nadam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbT9fEUZS0hn"
      },
      "source": [
        "---\n",
        "\n",
        "8.\tЗапустите процесс обучения сети с использованием проверочного набора (10% от обучающих данных) и выводом информации о процессе обучения. Установите 300 эпох обучения. Контролируйте значения метрики на обучающих и проверочных данных, убедитесь в отсутствии переобучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZKoilE3S-pc",
        "outputId": "6f0e2f4f-c068-40bd-80d8-db1dc8d7c5e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "383/383 [==============================] - 2s 2ms/step - loss: 56433352704.0000 - mae: 207416.7656 - val_loss: 55281864704.0000 - val_mae: 205380.5000\n",
            "Epoch 2/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 55306448896.0000 - mae: 204960.0469 - val_loss: 53067517952.0000 - val_mae: 200546.4688\n",
            "Epoch 3/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 51799588864.0000 - mae: 197046.8594 - val_loss: 48126038016.0000 - val_mae: 189128.6875\n",
            "Epoch 4/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 45684510720.0000 - mae: 182431.6719 - val_loss: 40886607872.0000 - val_mae: 171112.0000\n",
            "Epoch 5/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 37846384640.0000 - mae: 162292.4531 - val_loss: 32697995264.0000 - val_mae: 148803.6406\n",
            "Epoch 6/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 29725702144.0000 - mae: 139137.2031 - val_loss: 24966727680.0000 - val_mae: 125328.1172\n",
            "Epoch 7/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 22508978176.0000 - mae: 116174.2969 - val_loss: 18696802304.0000 - val_mae: 103953.5156\n",
            "Epoch 8/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 16976679936.0000 - mae: 97002.7500 - val_loss: 14377418752.0000 - val_mae: 87689.7422\n",
            "Epoch 9/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 13528328192.0000 - mae: 84922.7109 - val_loss: 12137025536.0000 - val_mae: 79889.6016\n",
            "Epoch 10/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 11807565824.0000 - mae: 79186.9844 - val_loss: 11081212928.0000 - val_mae: 76417.1016\n",
            "Epoch 11/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 10922341376.0000 - mae: 76268.6562 - val_loss: 10448765952.0000 - val_mae: 74286.9922\n",
            "Epoch 12/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 10329373696.0000 - mae: 74203.6562 - val_loss: 9936482304.0000 - val_mae: 72527.3672\n",
            "Epoch 13/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 9842232320.0000 - mae: 72362.1797 - val_loss: 9478688768.0000 - val_mae: 70786.1641\n",
            "Epoch 14/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 9410699264.0000 - mae: 70579.8672 - val_loss: 9048615936.0000 - val_mae: 69102.7109\n",
            "Epoch 15/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 9016164352.0000 - mae: 69004.1484 - val_loss: 8658864128.0000 - val_mae: 67555.1016\n",
            "Epoch 16/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 8651246592.0000 - mae: 67431.7422 - val_loss: 8303332352.0000 - val_mae: 66210.2969\n",
            "Epoch 17/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 8311144960.0000 - mae: 66060.5391 - val_loss: 7957597696.0000 - val_mae: 64874.9531\n",
            "Epoch 18/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 7989811712.0000 - mae: 64692.4844 - val_loss: 7631611904.0000 - val_mae: 63622.6523\n",
            "Epoch 19/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 7689404416.0000 - mae: 63428.1992 - val_loss: 7332387328.0000 - val_mae: 62436.2930\n",
            "Epoch 20/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 7405568000.0000 - mae: 62186.1523 - val_loss: 7064459264.0000 - val_mae: 61531.5898\n",
            "Epoch 21/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 7141514752.0000 - mae: 61159.8203 - val_loss: 6793219584.0000 - val_mae: 60431.2539\n",
            "Epoch 22/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6892119552.0000 - mae: 60098.6992 - val_loss: 6542364160.0000 - val_mae: 59452.0469\n",
            "Epoch 23/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6655825408.0000 - mae: 59063.8945 - val_loss: 6314812416.0000 - val_mae: 58646.3750\n",
            "Epoch 24/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6436369920.0000 - mae: 58183.9961 - val_loss: 6077704192.0000 - val_mae: 57657.2539\n",
            "Epoch 25/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6229093888.0000 - mae: 57292.0117 - val_loss: 5857168384.0000 - val_mae: 56710.2070\n",
            "Epoch 26/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6038893568.0000 - mae: 56437.5156 - val_loss: 5664368640.0000 - val_mae: 55984.7344\n",
            "Epoch 27/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5863044096.0000 - mae: 55707.5156 - val_loss: 5476947456.0000 - val_mae: 55068.4922\n",
            "Epoch 28/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5708288000.0000 - mae: 54949.7578 - val_loss: 5328555520.0000 - val_mae: 54498.0781\n",
            "Epoch 29/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5571201536.0000 - mae: 54406.9180 - val_loss: 5189681152.0000 - val_mae: 53787.3867\n",
            "Epoch 30/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5453651968.0000 - mae: 53806.8125 - val_loss: 5084309504.0000 - val_mae: 53430.7070\n",
            "Epoch 31/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5351525376.0000 - mae: 53408.2500 - val_loss: 4985156608.0000 - val_mae: 52922.9805\n",
            "Epoch 32/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5262256128.0000 - mae: 52962.6992 - val_loss: 4895387648.0000 - val_mae: 52428.1758\n",
            "Epoch 33/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5182951936.0000 - mae: 52563.5312 - val_loss: 4819474432.0000 - val_mae: 52000.7070\n",
            "Epoch 34/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5112991744.0000 - mae: 52208.6680 - val_loss: 4757412864.0000 - val_mae: 51675.9531\n",
            "Epoch 35/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5052004352.0000 - mae: 51877.7344 - val_loss: 4697984000.0000 - val_mae: 51318.3164\n",
            "Epoch 36/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4996017664.0000 - mae: 51659.8281 - val_loss: 4632236544.0000 - val_mae: 50706.1250\n",
            "Epoch 37/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4949389312.0000 - mae: 51304.2656 - val_loss: 4588024832.0000 - val_mae: 50433.1367\n",
            "Epoch 38/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4905174016.0000 - mae: 51083.0000 - val_loss: 4551224832.0000 - val_mae: 50192.3750\n",
            "Epoch 39/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4866878464.0000 - mae: 50798.4883 - val_loss: 4521876992.0000 - val_mae: 50054.7930\n",
            "Epoch 40/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4833319936.0000 - mae: 50704.5547 - val_loss: 4483511808.0000 - val_mae: 49657.1055\n",
            "Epoch 41/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4803532288.0000 - mae: 50463.9258 - val_loss: 4460517888.0000 - val_mae: 49439.7227\n",
            "Epoch 42/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4775804416.0000 - mae: 50288.5391 - val_loss: 4435173888.0000 - val_mae: 49210.0156\n",
            "Epoch 43/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4752200704.0000 - mae: 50145.4688 - val_loss: 4410670592.0000 - val_mae: 48984.1836\n",
            "Epoch 44/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4730569728.0000 - mae: 49950.4297 - val_loss: 4392864256.0000 - val_mae: 48844.1484\n",
            "Epoch 45/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4711120896.0000 - mae: 49897.8672 - val_loss: 4375491584.0000 - val_mae: 48651.8359\n",
            "Epoch 46/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4693500416.0000 - mae: 49729.9258 - val_loss: 4369922560.0000 - val_mae: 48619.8359\n",
            "Epoch 47/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4677577728.0000 - mae: 49644.3750 - val_loss: 4349914624.0000 - val_mae: 48365.6836\n",
            "Epoch 48/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4662854144.0000 - mae: 49481.0820 - val_loss: 4344739840.0000 - val_mae: 48317.3984\n",
            "Epoch 49/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4649509888.0000 - mae: 49405.7812 - val_loss: 4327114752.0000 - val_mae: 48114.6133\n",
            "Epoch 50/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4636525056.0000 - mae: 49331.1953 - val_loss: 4323482624.0000 - val_mae: 48090.4023\n",
            "Epoch 51/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4625515008.0000 - mae: 49272.0430 - val_loss: 4306415104.0000 - val_mae: 47854.3906\n",
            "Epoch 52/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4614360576.0000 - mae: 49063.3359 - val_loss: 4309153280.0000 - val_mae: 47935.0820\n",
            "Epoch 53/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4605106176.0000 - mae: 49097.8945 - val_loss: 4299822592.0000 - val_mae: 47792.1055\n",
            "Epoch 54/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4595814912.0000 - mae: 49028.6953 - val_loss: 4288144128.0000 - val_mae: 47629.7305\n",
            "Epoch 55/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4585459712.0000 - mae: 48910.6250 - val_loss: 4296156160.0000 - val_mae: 47741.2383\n",
            "Epoch 56/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4578093568.0000 - mae: 48898.0391 - val_loss: 4270035968.0000 - val_mae: 47423.5898\n",
            "Epoch 57/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4570225664.0000 - mae: 48799.0000 - val_loss: 4269025024.0000 - val_mae: 47393.3438\n",
            "Epoch 58/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4563211264.0000 - mae: 48776.3281 - val_loss: 4260551680.0000 - val_mae: 47299.3906\n",
            "Epoch 59/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4556563456.0000 - mae: 48698.8750 - val_loss: 4259410432.0000 - val_mae: 47291.2773\n",
            "Epoch 60/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4549762560.0000 - mae: 48610.1523 - val_loss: 4254180864.0000 - val_mae: 47221.2812\n",
            "Epoch 61/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4543421440.0000 - mae: 48582.3477 - val_loss: 4251859200.0000 - val_mae: 47243.9414\n",
            "Epoch 62/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4537869824.0000 - mae: 48577.9922 - val_loss: 4252062720.0000 - val_mae: 47103.2812\n",
            "Epoch 63/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4532057600.0000 - mae: 48478.9336 - val_loss: 4244623616.0000 - val_mae: 47081.9922\n",
            "Epoch 64/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4525626368.0000 - mae: 48484.0430 - val_loss: 4237683456.0000 - val_mae: 47033.9453\n",
            "Epoch 65/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4519625216.0000 - mae: 48444.0820 - val_loss: 4230502912.0000 - val_mae: 46874.8008\n",
            "Epoch 66/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4514657792.0000 - mae: 48373.7930 - val_loss: 4234237696.0000 - val_mae: 46895.9297\n",
            "Epoch 67/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4509770752.0000 - mae: 48315.9102 - val_loss: 4230526208.0000 - val_mae: 46817.6953\n",
            "Epoch 68/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4504357376.0000 - mae: 48316.3398 - val_loss: 4219597056.0000 - val_mae: 46710.3398\n",
            "Epoch 69/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4500603904.0000 - mae: 48196.1875 - val_loss: 4217252352.0000 - val_mae: 46758.2422\n",
            "Epoch 70/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4496093696.0000 - mae: 48188.9727 - val_loss: 4227793408.0000 - val_mae: 46846.9961\n",
            "Epoch 71/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4490961408.0000 - mae: 48194.2383 - val_loss: 4223861504.0000 - val_mae: 46745.5352\n",
            "Epoch 72/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4486870528.0000 - mae: 48103.4805 - val_loss: 4222307072.0000 - val_mae: 46831.6133\n",
            "Epoch 73/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4481543680.0000 - mae: 48167.6562 - val_loss: 4203742464.0000 - val_mae: 46579.1250\n",
            "Epoch 74/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4479430144.0000 - mae: 48028.3555 - val_loss: 4209364480.0000 - val_mae: 46584.6211\n",
            "Epoch 75/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4474433024.0000 - mae: 48030.5820 - val_loss: 4208563968.0000 - val_mae: 46607.4492\n",
            "Epoch 76/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4470043648.0000 - mae: 48029.1836 - val_loss: 4202862592.0000 - val_mae: 46462.6719\n",
            "Epoch 77/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4466459648.0000 - mae: 47953.6211 - val_loss: 4204666368.0000 - val_mae: 46571.3047\n",
            "Epoch 78/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4462385152.0000 - mae: 47962.0664 - val_loss: 4196193792.0000 - val_mae: 46469.5781\n",
            "Epoch 79/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4458690560.0000 - mae: 47879.1094 - val_loss: 4202852608.0000 - val_mae: 46534.1914\n",
            "Epoch 80/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4454906368.0000 - mae: 47879.5547 - val_loss: 4200606208.0000 - val_mae: 46547.2344\n",
            "Epoch 81/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4451779584.0000 - mae: 47885.8984 - val_loss: 4195073792.0000 - val_mae: 46465.6953\n",
            "Epoch 82/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4447602688.0000 - mae: 47864.6484 - val_loss: 4199037696.0000 - val_mae: 46379.6094\n",
            "Epoch 83/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4443900416.0000 - mae: 47797.5586 - val_loss: 4194969856.0000 - val_mae: 46307.9961\n",
            "Epoch 84/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4440781312.0000 - mae: 47716.8828 - val_loss: 4195455232.0000 - val_mae: 46451.6641\n",
            "Epoch 85/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4438074880.0000 - mae: 47742.5586 - val_loss: 4187704576.0000 - val_mae: 46342.6016\n",
            "Epoch 86/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4433836544.0000 - mae: 47652.6445 - val_loss: 4189179392.0000 - val_mae: 46487.5469\n",
            "Epoch 87/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4431420416.0000 - mae: 47747.1250 - val_loss: 4186373376.0000 - val_mae: 46243.5000\n",
            "Epoch 88/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4428104704.0000 - mae: 47638.7500 - val_loss: 4185746176.0000 - val_mae: 46295.0352\n",
            "Epoch 89/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4424848384.0000 - mae: 47673.1484 - val_loss: 4182877952.0000 - val_mae: 46222.5000\n",
            "Epoch 90/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4421788672.0000 - mae: 47525.9336 - val_loss: 4183926528.0000 - val_mae: 46340.4258\n",
            "Epoch 91/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4418939392.0000 - mae: 47654.1133 - val_loss: 4175485184.0000 - val_mae: 46220.7578\n",
            "Epoch 92/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4415464448.0000 - mae: 47606.5781 - val_loss: 4164607232.0000 - val_mae: 46123.6055\n",
            "Epoch 93/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4413428224.0000 - mae: 47561.6836 - val_loss: 4168447232.0000 - val_mae: 46094.5312\n",
            "Epoch 94/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4409847808.0000 - mae: 47465.9727 - val_loss: 4182327808.0000 - val_mae: 46204.2422\n",
            "Epoch 95/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4407300608.0000 - mae: 47513.2812 - val_loss: 4166635776.0000 - val_mae: 46108.7734\n",
            "Epoch 96/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4405176320.0000 - mae: 47500.8984 - val_loss: 4166095360.0000 - val_mae: 46129.6016\n",
            "Epoch 97/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4401306624.0000 - mae: 47483.4414 - val_loss: 4170955008.0000 - val_mae: 46144.4961\n",
            "Epoch 98/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4399249920.0000 - mae: 47469.0195 - val_loss: 4163639040.0000 - val_mae: 46014.8203\n",
            "Epoch 99/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4396689920.0000 - mae: 47414.1602 - val_loss: 4172052480.0000 - val_mae: 46071.6719\n",
            "Epoch 100/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4393788928.0000 - mae: 47403.5469 - val_loss: 4152403456.0000 - val_mae: 45980.0039\n",
            "Epoch 101/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4392271872.0000 - mae: 47390.6250 - val_loss: 4161663488.0000 - val_mae: 45993.3008\n",
            "Epoch 102/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4389050880.0000 - mae: 47340.6992 - val_loss: 4165340928.0000 - val_mae: 46020.3906\n",
            "Epoch 103/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4387171840.0000 - mae: 47323.1523 - val_loss: 4161328640.0000 - val_mae: 46048.7812\n",
            "Epoch 104/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4384634368.0000 - mae: 47326.3008 - val_loss: 4163252992.0000 - val_mae: 46101.6641\n",
            "Epoch 105/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4381982720.0000 - mae: 47334.6875 - val_loss: 4151975936.0000 - val_mae: 45972.3594\n",
            "Epoch 106/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4379851776.0000 - mae: 47306.2188 - val_loss: 4149061376.0000 - val_mae: 45946.3711\n",
            "Epoch 107/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4377244672.0000 - mae: 47292.6016 - val_loss: 4153298176.0000 - val_mae: 45919.7344\n",
            "Epoch 108/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4376121856.0000 - mae: 47241.0977 - val_loss: 4157160960.0000 - val_mae: 45971.1797\n",
            "Epoch 109/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4373305856.0000 - mae: 47297.1094 - val_loss: 4142689280.0000 - val_mae: 45843.2461\n",
            "Epoch 110/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4372037120.0000 - mae: 47211.7969 - val_loss: 4147630336.0000 - val_mae: 45886.9102\n",
            "Epoch 111/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4369320448.0000 - mae: 47167.2266 - val_loss: 4155975424.0000 - val_mae: 45984.7891\n",
            "Epoch 112/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4366909440.0000 - mae: 47217.2461 - val_loss: 4155074816.0000 - val_mae: 45864.8750\n",
            "Epoch 113/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4365313024.0000 - mae: 47155.3203 - val_loss: 4148564480.0000 - val_mae: 45878.8086\n",
            "Epoch 114/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4363266048.0000 - mae: 47156.4922 - val_loss: 4150157312.0000 - val_mae: 45889.1445\n",
            "Epoch 115/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4361549312.0000 - mae: 47150.7930 - val_loss: 4144242176.0000 - val_mae: 45829.2422\n",
            "Epoch 116/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4358759424.0000 - mae: 47146.0977 - val_loss: 4149793024.0000 - val_mae: 45841.8711\n",
            "Epoch 117/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4357094400.0000 - mae: 47081.3438 - val_loss: 4146028288.0000 - val_mae: 45885.9180\n",
            "Epoch 118/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4355328512.0000 - mae: 47126.4609 - val_loss: 4139780864.0000 - val_mae: 45838.5547\n",
            "Epoch 119/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4353342976.0000 - mae: 47101.9766 - val_loss: 4146829056.0000 - val_mae: 45846.1016\n",
            "Epoch 120/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4351506944.0000 - mae: 47066.4102 - val_loss: 4133069824.0000 - val_mae: 45748.8984\n",
            "Epoch 121/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4349597184.0000 - mae: 47035.2578 - val_loss: 4135616000.0000 - val_mae: 45838.8516\n",
            "Epoch 122/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4347376128.0000 - mae: 47115.7656 - val_loss: 4133314560.0000 - val_mae: 45665.2266\n",
            "Epoch 123/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4346394624.0000 - mae: 46991.2148 - val_loss: 4125878272.0000 - val_mae: 45643.1211\n",
            "Epoch 124/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4343416832.0000 - mae: 46967.2891 - val_loss: 4142785024.0000 - val_mae: 45802.9336\n",
            "Epoch 125/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4342721536.0000 - mae: 47042.8867 - val_loss: 4135495936.0000 - val_mae: 45698.4688\n",
            "Epoch 126/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4340682240.0000 - mae: 46958.2109 - val_loss: 4139595008.0000 - val_mae: 45730.4688\n",
            "Epoch 127/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4339488256.0000 - mae: 46952.1797 - val_loss: 4130009600.0000 - val_mae: 45679.1641\n",
            "Epoch 128/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4336738816.0000 - mae: 46960.8438 - val_loss: 4137085952.0000 - val_mae: 45713.6367\n",
            "Epoch 129/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4336103424.0000 - mae: 46981.4883 - val_loss: 4125217792.0000 - val_mae: 45619.6172\n",
            "Epoch 130/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4333271552.0000 - mae: 46941.2930 - val_loss: 4117441024.0000 - val_mae: 45589.4219\n",
            "Epoch 131/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4331824128.0000 - mae: 46868.2031 - val_loss: 4138966528.0000 - val_mae: 45672.1094\n",
            "Epoch 132/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4330068480.0000 - mae: 46929.0469 - val_loss: 4121917952.0000 - val_mae: 45630.1094\n",
            "Epoch 133/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4329390592.0000 - mae: 46884.4531 - val_loss: 4132478208.0000 - val_mae: 45698.0938\n",
            "Epoch 134/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4326909440.0000 - mae: 46892.7891 - val_loss: 4119765760.0000 - val_mae: 45581.6836\n",
            "Epoch 135/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4325936128.0000 - mae: 46874.6367 - val_loss: 4116683520.0000 - val_mae: 45513.1367\n",
            "Epoch 136/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4324846592.0000 - mae: 46823.9570 - val_loss: 4125860096.0000 - val_mae: 45636.7852\n",
            "Epoch 137/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4322279424.0000 - mae: 46878.3516 - val_loss: 4118456064.0000 - val_mae: 45589.8750\n",
            "Epoch 138/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4320820736.0000 - mae: 46814.2344 - val_loss: 4118763264.0000 - val_mae: 45549.1758\n",
            "Epoch 139/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4319191552.0000 - mae: 46813.4961 - val_loss: 4126830080.0000 - val_mae: 45620.9727\n",
            "Epoch 140/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4317952512.0000 - mae: 46818.9766 - val_loss: 4117533952.0000 - val_mae: 45526.0898\n",
            "Epoch 141/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4317192192.0000 - mae: 46796.5742 - val_loss: 4117556736.0000 - val_mae: 45528.9727\n",
            "Epoch 142/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4315099136.0000 - mae: 46794.9648 - val_loss: 4115059712.0000 - val_mae: 45493.2578\n",
            "Epoch 143/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4313847296.0000 - mae: 46768.6680 - val_loss: 4115447552.0000 - val_mae: 45505.8438\n",
            "Epoch 144/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4312546816.0000 - mae: 46761.8242 - val_loss: 4111336192.0000 - val_mae: 45509.1641\n",
            "Epoch 145/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4310948864.0000 - mae: 46738.7969 - val_loss: 4117738240.0000 - val_mae: 45555.9023\n",
            "Epoch 146/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4310076928.0000 - mae: 46757.1445 - val_loss: 4115789056.0000 - val_mae: 45567.3398\n",
            "Epoch 147/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4307131904.0000 - mae: 46758.3320 - val_loss: 4107615744.0000 - val_mae: 45421.1602\n",
            "Epoch 148/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4307363328.0000 - mae: 46687.6953 - val_loss: 4111547904.0000 - val_mae: 45505.8711\n",
            "Epoch 149/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4304888320.0000 - mae: 46680.4688 - val_loss: 4118274816.0000 - val_mae: 45547.6328\n",
            "Epoch 150/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4304073216.0000 - mae: 46671.0742 - val_loss: 4114593280.0000 - val_mae: 45589.5391\n",
            "Epoch 151/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4302726656.0000 - mae: 46705.5547 - val_loss: 4106523904.0000 - val_mae: 45533.6367\n",
            "Epoch 152/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4301381120.0000 - mae: 46652.4844 - val_loss: 4112110336.0000 - val_mae: 45594.7109\n",
            "Epoch 153/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4300443648.0000 - mae: 46678.3203 - val_loss: 4113012480.0000 - val_mae: 45570.0898\n",
            "Epoch 154/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4299042816.0000 - mae: 46664.7461 - val_loss: 4104474624.0000 - val_mae: 45498.3750\n",
            "Epoch 155/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4297065984.0000 - mae: 46672.6758 - val_loss: 4108320256.0000 - val_mae: 45427.7305\n",
            "Epoch 156/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4295861760.0000 - mae: 46599.5547 - val_loss: 4114163968.0000 - val_mae: 45518.0039\n",
            "Epoch 157/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4294323456.0000 - mae: 46636.7578 - val_loss: 4103561216.0000 - val_mae: 45438.6328\n",
            "Epoch 158/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4293314560.0000 - mae: 46602.3047 - val_loss: 4109389312.0000 - val_mae: 45450.7070\n",
            "Epoch 159/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4291503872.0000 - mae: 46617.2070 - val_loss: 4113955328.0000 - val_mae: 45419.8164\n",
            "Epoch 160/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4290674688.0000 - mae: 46545.6328 - val_loss: 4118078208.0000 - val_mae: 45568.7812\n",
            "Epoch 161/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4289895424.0000 - mae: 46634.3984 - val_loss: 4092563712.0000 - val_mae: 45247.8867\n",
            "Epoch 162/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4288911616.0000 - mae: 46528.3711 - val_loss: 4100777472.0000 - val_mae: 45441.3672\n",
            "Epoch 163/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4286723584.0000 - mae: 46595.6328 - val_loss: 4111702016.0000 - val_mae: 45438.4570\n",
            "Epoch 164/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4285715200.0000 - mae: 46549.7891 - val_loss: 4104608000.0000 - val_mae: 45454.1914\n",
            "Epoch 165/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4283740416.0000 - mae: 46571.8164 - val_loss: 4099325696.0000 - val_mae: 45306.7422\n",
            "Epoch 166/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4283070720.0000 - mae: 46490.6094 - val_loss: 4105026304.0000 - val_mae: 45471.2891\n",
            "Epoch 167/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4282651904.0000 - mae: 46578.2227 - val_loss: 4095834624.0000 - val_mae: 45350.3047\n",
            "Epoch 168/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4281175552.0000 - mae: 46513.9141 - val_loss: 4092489216.0000 - val_mae: 45273.8125\n",
            "Epoch 169/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4278734592.0000 - mae: 46441.8711 - val_loss: 4106507264.0000 - val_mae: 45522.7812\n",
            "Epoch 170/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4278683136.0000 - mae: 46512.1523 - val_loss: 4106483456.0000 - val_mae: 45446.2852\n",
            "Epoch 171/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4277201408.0000 - mae: 46519.7422 - val_loss: 4091742976.0000 - val_mae: 45330.1953\n",
            "Epoch 172/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4275556864.0000 - mae: 46458.8828 - val_loss: 4088313344.0000 - val_mae: 45359.1641\n",
            "Epoch 173/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4275657984.0000 - mae: 46470.9609 - val_loss: 4099525888.0000 - val_mae: 45396.3164\n",
            "Epoch 174/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4274353408.0000 - mae: 46476.2969 - val_loss: 4089282048.0000 - val_mae: 45181.1953\n",
            "Epoch 175/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4274180864.0000 - mae: 46400.9297 - val_loss: 4094979584.0000 - val_mae: 45353.6680\n",
            "Epoch 176/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4271423232.0000 - mae: 46384.2969 - val_loss: 4100727808.0000 - val_mae: 45446.9844\n",
            "Epoch 177/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4270248960.0000 - mae: 46483.7734 - val_loss: 4091143424.0000 - val_mae: 45248.0508\n",
            "Epoch 178/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4269510656.0000 - mae: 46368.2617 - val_loss: 4098948608.0000 - val_mae: 45403.2891\n",
            "Epoch 179/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4268249600.0000 - mae: 46450.0195 - val_loss: 4094177792.0000 - val_mae: 45339.9297\n",
            "Epoch 180/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4267879424.0000 - mae: 46420.8203 - val_loss: 4082407936.0000 - val_mae: 45200.2383\n",
            "Epoch 181/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4266327552.0000 - mae: 46406.8594 - val_loss: 4079569408.0000 - val_mae: 45164.3047\n",
            "Epoch 182/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4265212672.0000 - mae: 46349.5000 - val_loss: 4088372480.0000 - val_mae: 45337.3867\n",
            "Epoch 183/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4263894528.0000 - mae: 46387.5625 - val_loss: 4083072768.0000 - val_mae: 45259.4805\n",
            "Epoch 184/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4263187456.0000 - mae: 46332.9062 - val_loss: 4082488832.0000 - val_mae: 45268.4375\n",
            "Epoch 185/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4263141632.0000 - mae: 46351.4961 - val_loss: 4088282112.0000 - val_mae: 45311.0781\n",
            "Epoch 186/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4261600256.0000 - mae: 46377.5781 - val_loss: 4079292928.0000 - val_mae: 45230.4375\n",
            "Epoch 187/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4259782656.0000 - mae: 46355.8398 - val_loss: 4082938368.0000 - val_mae: 45271.2812\n",
            "Epoch 188/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4259306496.0000 - mae: 46353.1328 - val_loss: 4080271360.0000 - val_mae: 45189.4297\n",
            "Epoch 189/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4257395712.0000 - mae: 46272.8789 - val_loss: 4088462848.0000 - val_mae: 45220.7031\n",
            "Epoch 190/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4256524288.0000 - mae: 46321.7734 - val_loss: 4095093248.0000 - val_mae: 45358.0781\n",
            "Epoch 191/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4255815936.0000 - mae: 46383.5820 - val_loss: 4075853568.0000 - val_mae: 45077.3750\n",
            "Epoch 192/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4254246656.0000 - mae: 46227.2891 - val_loss: 4076548608.0000 - val_mae: 45220.4258\n",
            "Epoch 193/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4254326528.0000 - mae: 46273.1875 - val_loss: 4083960320.0000 - val_mae: 45269.0312\n",
            "Epoch 194/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4253075200.0000 - mae: 46312.6602 - val_loss: 4080714752.0000 - val_mae: 45258.5273\n",
            "Epoch 195/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4251433472.0000 - mae: 46294.3984 - val_loss: 4085664256.0000 - val_mae: 45142.7461\n",
            "Epoch 196/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4250109952.0000 - mae: 46244.2969 - val_loss: 4078619392.0000 - val_mae: 45242.1211\n",
            "Epoch 197/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4249971712.0000 - mae: 46233.2070 - val_loss: 4079096320.0000 - val_mae: 45274.0859\n",
            "Epoch 198/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4248783104.0000 - mae: 46251.7344 - val_loss: 4071282432.0000 - val_mae: 45170.1211\n",
            "Epoch 199/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4248492032.0000 - mae: 46221.7773 - val_loss: 4074582784.0000 - val_mae: 45239.0430\n",
            "Epoch 200/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4246920704.0000 - mae: 46251.5039 - val_loss: 4069792512.0000 - val_mae: 45144.7344\n",
            "Epoch 201/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4245635584.0000 - mae: 46219.1211 - val_loss: 4069329920.0000 - val_mae: 45161.7109\n",
            "Epoch 202/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4244802816.0000 - mae: 46277.6484 - val_loss: 4062352384.0000 - val_mae: 44989.9688\n",
            "Epoch 203/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4243674880.0000 - mae: 46205.0664 - val_loss: 4075401984.0000 - val_mae: 45077.0898\n",
            "Epoch 204/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4242464256.0000 - mae: 46181.8711 - val_loss: 4071587328.0000 - val_mae: 45036.6797\n",
            "Epoch 205/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4241646080.0000 - mae: 46177.4961 - val_loss: 4076987648.0000 - val_mae: 45117.7734\n",
            "Epoch 206/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4239784448.0000 - mae: 46176.1953 - val_loss: 4063061504.0000 - val_mae: 45122.1445\n",
            "Epoch 207/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4240517376.0000 - mae: 46151.9375 - val_loss: 4067425024.0000 - val_mae: 45198.4922\n",
            "Epoch 208/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4239434496.0000 - mae: 46175.3516 - val_loss: 4077512192.0000 - val_mae: 45270.0586\n",
            "Epoch 209/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4238083840.0000 - mae: 46202.9375 - val_loss: 4068274688.0000 - val_mae: 45103.9688\n",
            "Epoch 210/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4237049600.0000 - mae: 46144.7305 - val_loss: 4077561344.0000 - val_mae: 45172.4570\n",
            "Epoch 211/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4236771072.0000 - mae: 46133.2656 - val_loss: 4076993280.0000 - val_mae: 45202.4766\n",
            "Epoch 212/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4235405312.0000 - mae: 46144.3281 - val_loss: 4062602496.0000 - val_mae: 45149.3203\n",
            "Epoch 213/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4234459904.0000 - mae: 46152.0469 - val_loss: 4058792448.0000 - val_mae: 45063.7969\n",
            "Epoch 214/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4233971712.0000 - mae: 46129.2930 - val_loss: 4060004096.0000 - val_mae: 45031.3867\n",
            "Epoch 215/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4232398080.0000 - mae: 46093.2344 - val_loss: 4056608512.0000 - val_mae: 45011.4531\n",
            "Epoch 216/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4231099648.0000 - mae: 46122.5156 - val_loss: 4058233600.0000 - val_mae: 45003.9766\n",
            "Epoch 217/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4231086848.0000 - mae: 46114.2734 - val_loss: 4057465600.0000 - val_mae: 44989.1562\n",
            "Epoch 218/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4230225152.0000 - mae: 46066.6289 - val_loss: 4060775680.0000 - val_mae: 45072.5039\n",
            "Epoch 219/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4228161024.0000 - mae: 46042.6094 - val_loss: 4069370368.0000 - val_mae: 45128.9688\n",
            "Epoch 220/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4227546368.0000 - mae: 46125.3789 - val_loss: 4050886656.0000 - val_mae: 44936.2656\n",
            "Epoch 221/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4226466048.0000 - mae: 46036.3828 - val_loss: 4056752896.0000 - val_mae: 45087.5078\n",
            "Epoch 222/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4226397952.0000 - mae: 46076.8242 - val_loss: 4055282176.0000 - val_mae: 44944.0312\n",
            "Epoch 223/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4225153792.0000 - mae: 46009.2969 - val_loss: 4060057088.0000 - val_mae: 45123.1406\n",
            "Epoch 224/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4224597248.0000 - mae: 46065.4648 - val_loss: 4057759232.0000 - val_mae: 45086.2930\n",
            "Epoch 225/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4223436288.0000 - mae: 46047.4141 - val_loss: 4062642176.0000 - val_mae: 45073.6875\n",
            "Epoch 226/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4222138880.0000 - mae: 46031.5039 - val_loss: 4055971072.0000 - val_mae: 45086.4805\n",
            "Epoch 227/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4222287360.0000 - mae: 46016.6523 - val_loss: 4056112128.0000 - val_mae: 45072.9492\n",
            "Epoch 228/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4219780352.0000 - mae: 46071.5469 - val_loss: 4041165568.0000 - val_mae: 44867.3945\n",
            "Epoch 229/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4219857408.0000 - mae: 45983.0547 - val_loss: 4055808768.0000 - val_mae: 44916.5000\n",
            "Epoch 230/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4220112384.0000 - mae: 45983.6484 - val_loss: 4051382784.0000 - val_mae: 44956.3516\n",
            "Epoch 231/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4217412352.0000 - mae: 45959.0898 - val_loss: 4061902080.0000 - val_mae: 45158.0859\n",
            "Epoch 232/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4217800448.0000 - mae: 46020.8906 - val_loss: 4054711040.0000 - val_mae: 45028.4219\n",
            "Epoch 233/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4215674112.0000 - mae: 46004.2500 - val_loss: 4040677120.0000 - val_mae: 44920.7070\n",
            "Epoch 234/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4215344384.0000 - mae: 45972.5078 - val_loss: 4046117120.0000 - val_mae: 44898.8125\n",
            "Epoch 235/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4213944320.0000 - mae: 45944.1094 - val_loss: 4049083904.0000 - val_mae: 44987.0195\n",
            "Epoch 236/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4214314240.0000 - mae: 45944.5273 - val_loss: 4049802240.0000 - val_mae: 44987.0430\n",
            "Epoch 237/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4211812864.0000 - mae: 45991.0469 - val_loss: 4055578624.0000 - val_mae: 44933.2305\n",
            "Epoch 238/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4212294912.0000 - mae: 45923.7695 - val_loss: 4041496832.0000 - val_mae: 44941.1016\n",
            "Epoch 239/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4210466048.0000 - mae: 45938.4375 - val_loss: 4045505024.0000 - val_mae: 44891.8164\n",
            "Epoch 240/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4209439744.0000 - mae: 45926.4141 - val_loss: 4055642880.0000 - val_mae: 44961.1055\n",
            "Epoch 241/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4209857280.0000 - mae: 45886.4688 - val_loss: 4048448512.0000 - val_mae: 44934.5781\n",
            "Epoch 242/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4208850432.0000 - mae: 45935.7969 - val_loss: 4042797824.0000 - val_mae: 44880.8047\n",
            "Epoch 243/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4207057664.0000 - mae: 45876.9844 - val_loss: 4053558784.0000 - val_mae: 45031.0117\n",
            "Epoch 244/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4205579008.0000 - mae: 45932.6055 - val_loss: 4043930112.0000 - val_mae: 44818.2812\n",
            "Epoch 245/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4206064896.0000 - mae: 45851.0938 - val_loss: 4039927808.0000 - val_mae: 44907.2422\n",
            "Epoch 246/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4204583168.0000 - mae: 45886.7930 - val_loss: 4040067840.0000 - val_mae: 44887.1484\n",
            "Epoch 247/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4203215872.0000 - mae: 45857.1875 - val_loss: 4050391296.0000 - val_mae: 44970.4453\n",
            "Epoch 248/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4202807808.0000 - mae: 45872.3516 - val_loss: 4040397312.0000 - val_mae: 44937.0156\n",
            "Epoch 249/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4201528832.0000 - mae: 45882.5977 - val_loss: 4040471040.0000 - val_mae: 44895.9648\n",
            "Epoch 250/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4201003008.0000 - mae: 45879.3516 - val_loss: 4033477376.0000 - val_mae: 44800.0781\n",
            "Epoch 251/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4200542464.0000 - mae: 45840.0000 - val_loss: 4037332992.0000 - val_mae: 44836.6016\n",
            "Epoch 252/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4198614784.0000 - mae: 45831.4492 - val_loss: 4038949632.0000 - val_mae: 44819.5977\n",
            "Epoch 253/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4198923776.0000 - mae: 45833.7891 - val_loss: 4038209280.0000 - val_mae: 44807.8320\n",
            "Epoch 254/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4196459776.0000 - mae: 45778.3789 - val_loss: 4031779328.0000 - val_mae: 44881.9062\n",
            "Epoch 255/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4196012800.0000 - mae: 45798.6133 - val_loss: 4034387968.0000 - val_mae: 44854.8164\n",
            "Epoch 256/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4194645248.0000 - mae: 45835.0859 - val_loss: 4033934336.0000 - val_mae: 44852.0781\n",
            "Epoch 257/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4194081536.0000 - mae: 45793.0039 - val_loss: 4036267520.0000 - val_mae: 44834.5078\n",
            "Epoch 258/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4192682496.0000 - mae: 45799.8867 - val_loss: 4033287168.0000 - val_mae: 44821.6094\n",
            "Epoch 259/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4192047872.0000 - mae: 45755.5703 - val_loss: 4023538688.0000 - val_mae: 44730.8516\n",
            "Epoch 260/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4190556416.0000 - mae: 45769.6328 - val_loss: 4028486656.0000 - val_mae: 44852.3633\n",
            "Epoch 261/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4189102848.0000 - mae: 45757.6797 - val_loss: 4033416192.0000 - val_mae: 44848.2578\n",
            "Epoch 262/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4188512768.0000 - mae: 45776.0781 - val_loss: 4029868288.0000 - val_mae: 44817.6133\n",
            "Epoch 263/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4186883840.0000 - mae: 45722.5508 - val_loss: 4040013056.0000 - val_mae: 44982.4102\n",
            "Epoch 264/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4186748672.0000 - mae: 45764.0430 - val_loss: 4026694400.0000 - val_mae: 44849.1836\n",
            "Epoch 265/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4185173248.0000 - mae: 45721.4727 - val_loss: 4036264448.0000 - val_mae: 44887.6914\n",
            "Epoch 266/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4184239360.0000 - mae: 45780.5547 - val_loss: 4023405056.0000 - val_mae: 44727.3828\n",
            "Epoch 267/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4184033024.0000 - mae: 45754.4844 - val_loss: 4017196544.0000 - val_mae: 44633.8164\n",
            "Epoch 268/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4180728320.0000 - mae: 45611.5039 - val_loss: 4030907392.0000 - val_mae: 44913.4688\n",
            "Epoch 269/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4181409280.0000 - mae: 45761.9727 - val_loss: 4019789056.0000 - val_mae: 44735.5547\n",
            "Epoch 270/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4180547328.0000 - mae: 45696.2305 - val_loss: 4018640128.0000 - val_mae: 44783.9766\n",
            "Epoch 271/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4179203840.0000 - mae: 45679.4648 - val_loss: 4015882240.0000 - val_mae: 44802.1016\n",
            "Epoch 272/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4177325568.0000 - mae: 45659.7422 - val_loss: 4028661248.0000 - val_mae: 44878.7305\n",
            "Epoch 273/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4177079296.0000 - mae: 45747.9219 - val_loss: 4012539392.0000 - val_mae: 44681.8789\n",
            "Epoch 274/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4175957760.0000 - mae: 45655.6719 - val_loss: 4025023744.0000 - val_mae: 44802.1914\n",
            "Epoch 275/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4174896896.0000 - mae: 45648.0664 - val_loss: 4016549888.0000 - val_mae: 44795.3984\n",
            "Epoch 276/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4173891840.0000 - mae: 45713.0820 - val_loss: 4009830912.0000 - val_mae: 44602.8359\n",
            "Epoch 277/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4173618944.0000 - mae: 45616.4961 - val_loss: 4009250304.0000 - val_mae: 44701.0469\n",
            "Epoch 278/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4171770624.0000 - mae: 45662.9922 - val_loss: 4013097472.0000 - val_mae: 44666.5039\n",
            "Epoch 279/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4170846976.0000 - mae: 45611.6797 - val_loss: 4018639104.0000 - val_mae: 44767.7812\n",
            "Epoch 280/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4170103552.0000 - mae: 45604.4922 - val_loss: 4027326464.0000 - val_mae: 44826.1367\n",
            "Epoch 281/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4169277696.0000 - mae: 45654.2695 - val_loss: 4009301248.0000 - val_mae: 44702.0195\n",
            "Epoch 282/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4167893504.0000 - mae: 45610.8086 - val_loss: 4009624832.0000 - val_mae: 44719.1914\n",
            "Epoch 283/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4167056896.0000 - mae: 45594.0391 - val_loss: 4015658752.0000 - val_mae: 44769.0625\n",
            "Epoch 284/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4165489152.0000 - mae: 45602.7617 - val_loss: 4005574144.0000 - val_mae: 44623.4609\n",
            "Epoch 285/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4164103680.0000 - mae: 45578.1328 - val_loss: 4010944768.0000 - val_mae: 44708.6953\n",
            "Epoch 286/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4163057408.0000 - mae: 45560.5859 - val_loss: 4009419520.0000 - val_mae: 44796.8203\n",
            "Epoch 287/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4163028224.0000 - mae: 45617.9766 - val_loss: 4008546560.0000 - val_mae: 44608.0000\n",
            "Epoch 288/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4160718336.0000 - mae: 45497.3242 - val_loss: 4000545280.0000 - val_mae: 44674.9766\n",
            "Epoch 289/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4160389376.0000 - mae: 45566.8516 - val_loss: 4004450048.0000 - val_mae: 44661.5859\n",
            "Epoch 290/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4158680064.0000 - mae: 45538.8555 - val_loss: 4004408064.0000 - val_mae: 44710.3828\n",
            "Epoch 291/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4157042432.0000 - mae: 45589.3945 - val_loss: 4000496640.0000 - val_mae: 44560.8125\n",
            "Epoch 292/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4156128512.0000 - mae: 45562.6211 - val_loss: 4001152512.0000 - val_mae: 44492.6250\n",
            "Epoch 293/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4155436032.0000 - mae: 45475.6562 - val_loss: 4008866816.0000 - val_mae: 44597.7969\n",
            "Epoch 294/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4155672832.0000 - mae: 45539.7422 - val_loss: 4004475392.0000 - val_mae: 44646.9492\n",
            "Epoch 295/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4153485568.0000 - mae: 45505.7578 - val_loss: 3999342080.0000 - val_mae: 44599.5234\n",
            "Epoch 296/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4152574464.0000 - mae: 45515.2461 - val_loss: 3997798656.0000 - val_mae: 44593.4453\n",
            "Epoch 297/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4150643200.0000 - mae: 45463.1484 - val_loss: 4003374848.0000 - val_mae: 44683.4766\n",
            "Epoch 298/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4150221312.0000 - mae: 45512.1680 - val_loss: 3998276096.0000 - val_mae: 44601.6445\n",
            "Epoch 299/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4148520704.0000 - mae: 45497.2617 - val_loss: 3993151232.0000 - val_mae: 44517.7070\n",
            "Epoch 300/300\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4147528192.0000 - mae: 45444.1250 - val_loss: 4003413760.0000 - val_mae: 44672.3203\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=300, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTUASwVAUHJV"
      },
      "source": [
        "---\n",
        "\n",
        "9.\tВыполните оценку качества обученной модели на тестовых данных. Для ИНС с описанной выше архитектурой и параметрами обучения должно получиться значение около 45000 (может варьироваться в зависимости от способа разбиения исходного набора)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "fLFD0WhVUME_",
        "outputId": "83d9e1f4-01d4-4c99-97c2-1f1783f7b81a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "107/107 [==============================] - 0s 1ms/step - loss: 4045305856.0000 - mae: 45137.2383\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[4045305856.0, 45137.23828125]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['mae'])\n",
        "plt.plot(history.history['val_mae'])\n",
        "plt.title('Model MAE')\n",
        "plt.ylabel('MAE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Y4VTNNTt1t",
        "outputId": "d2a717d1-fdbf-4db4-aa62-791fdfbe1f96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[113420.89],\n",
              "       [260540.3 ],\n",
              "       [299244.88],\n",
              "       [148666.78],\n",
              "       [323745.  ]], dtype=float32)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_test)[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qkn265nT5kx",
        "outputId": "69641887-129e-45b9-ca23-de7943e7e505"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([127100., 185100., 223100.,  97300., 350000.])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[-5:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5NK8T5jUUbX"
      },
      "source": [
        "---\n",
        "\n",
        "10.\tИзменяя параметры архитектуры ИНС (в рамках RNN) и параметры обучения, постарайтесь добиться $MAE<37000$ на тестовых данных. Можно изменять:<br>• количество слоев ИНС;<br>• количество нейронов в скрытых слоях;<br>• функции активации;<br>• оптимизатор;<br>• размер подвыборок (батчей);<br>• количество эпох обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9n3EFBVUWXj"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(80, activation='relu', input_shape=(8,)))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxMEF08GgKiM",
        "outputId": "cb9b9109-733f-4aa6-adf0-361e678e90d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 80)                720       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 200)               16200     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 100)               20100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 37,121\n",
            "Trainable params: 37,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlTBe1i6gQcm",
        "outputId": "3f717984-9c99-422b-a0c4-ad62dc6a2e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 37629521920.0000 - mae: 156507.2656 - val_loss: 12350181376.0000 - val_mae: 80712.6328\n",
            "Epoch 2/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 9494153216.0000 - mae: 70328.1172 - val_loss: 7466958336.0000 - val_mae: 62425.4688\n",
            "Epoch 3/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 6805853184.0000 - mae: 59447.4297 - val_loss: 5831752704.0000 - val_mae: 56553.9297\n",
            "Epoch 4/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5640472576.0000 - mae: 54353.5742 - val_loss: 4946806272.0000 - val_mae: 52422.5117\n",
            "Epoch 5/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 5040174592.0000 - mae: 51523.5664 - val_loss: 4566258176.0000 - val_mae: 50464.7070\n",
            "Epoch 6/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4739322880.0000 - mae: 49884.9102 - val_loss: 4357029888.0000 - val_mae: 48544.8906\n",
            "Epoch 7/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4591379968.0000 - mae: 48960.4609 - val_loss: 4376400896.0000 - val_mae: 48772.6406\n",
            "Epoch 8/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4523355136.0000 - mae: 48560.3516 - val_loss: 4280168960.0000 - val_mae: 47391.3438\n",
            "Epoch 9/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4475691008.0000 - mae: 48049.5586 - val_loss: 4212764672.0000 - val_mae: 47134.6406\n",
            "Epoch 10/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4437095424.0000 - mae: 47853.1562 - val_loss: 4261181184.0000 - val_mae: 47691.2695\n",
            "Epoch 11/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4418083840.0000 - mae: 47658.8281 - val_loss: 4303488512.0000 - val_mae: 47343.9219\n",
            "Epoch 12/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4387894272.0000 - mae: 47378.2578 - val_loss: 4156057088.0000 - val_mae: 46177.3516\n",
            "Epoch 13/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4370053120.0000 - mae: 47272.5195 - val_loss: 4102876672.0000 - val_mae: 45809.6367\n",
            "Epoch 14/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4357852160.0000 - mae: 47092.4453 - val_loss: 4116352512.0000 - val_mae: 46016.5195\n",
            "Epoch 15/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4340209152.0000 - mae: 46980.4492 - val_loss: 4116102912.0000 - val_mae: 46163.7461\n",
            "Epoch 16/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4334745088.0000 - mae: 46950.3945 - val_loss: 4094764800.0000 - val_mae: 45555.6016\n",
            "Epoch 17/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4310509056.0000 - mae: 46708.6523 - val_loss: 4187514880.0000 - val_mae: 46071.5234\n",
            "Epoch 18/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4301327872.0000 - mae: 46647.0938 - val_loss: 4076721664.0000 - val_mae: 45468.8984\n",
            "Epoch 19/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4292576512.0000 - mae: 46586.2188 - val_loss: 4069905920.0000 - val_mae: 45395.5547\n",
            "Epoch 20/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4281144320.0000 - mae: 46512.9531 - val_loss: 4102791168.0000 - val_mae: 45613.8086\n",
            "Epoch 21/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4272926976.0000 - mae: 46474.0117 - val_loss: 4038094336.0000 - val_mae: 44960.5234\n",
            "Epoch 22/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4266383616.0000 - mae: 46354.8164 - val_loss: 4023181824.0000 - val_mae: 45040.1211\n",
            "Epoch 23/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4254546176.0000 - mae: 46253.6055 - val_loss: 4019828224.0000 - val_mae: 44934.9688\n",
            "Epoch 24/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4250159616.0000 - mae: 46253.7305 - val_loss: 4104292352.0000 - val_mae: 45624.1836\n",
            "Epoch 25/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4242830336.0000 - mae: 46199.8555 - val_loss: 4038483968.0000 - val_mae: 44800.7109\n",
            "Epoch 26/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4231717632.0000 - mae: 46062.5508 - val_loss: 4112218880.0000 - val_mae: 45424.7695\n",
            "Epoch 27/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4226097664.0000 - mae: 46052.3242 - val_loss: 4024682496.0000 - val_mae: 44829.4453\n",
            "Epoch 28/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4212200960.0000 - mae: 45951.4570 - val_loss: 4165810176.0000 - val_mae: 45614.5703\n",
            "Epoch 29/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4209441792.0000 - mae: 45902.1172 - val_loss: 4024571904.0000 - val_mae: 45248.5547\n",
            "Epoch 30/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4204571136.0000 - mae: 45828.5234 - val_loss: 4164310784.0000 - val_mae: 46342.8867\n",
            "Epoch 31/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4201716992.0000 - mae: 45921.1836 - val_loss: 3986358784.0000 - val_mae: 44644.1133\n",
            "Epoch 32/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4200165632.0000 - mae: 45766.7539 - val_loss: 4071187712.0000 - val_mae: 45480.4570\n",
            "Epoch 33/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4183108864.0000 - mae: 45747.2578 - val_loss: 4045228800.0000 - val_mae: 44320.4531\n",
            "Epoch 34/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4184748032.0000 - mae: 45671.3477 - val_loss: 4013925120.0000 - val_mae: 44606.2188\n",
            "Epoch 35/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4174356736.0000 - mae: 45667.7539 - val_loss: 4002717952.0000 - val_mae: 44317.6719\n",
            "Epoch 36/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4169680640.0000 - mae: 45567.5156 - val_loss: 4014843392.0000 - val_mae: 44916.5508\n",
            "Epoch 37/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4169026048.0000 - mae: 45504.4805 - val_loss: 4002955520.0000 - val_mae: 44934.5469\n",
            "Epoch 38/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4167406080.0000 - mae: 45550.8984 - val_loss: 4030347520.0000 - val_mae: 45170.7812\n",
            "Epoch 39/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4152094720.0000 - mae: 45475.3242 - val_loss: 3971416064.0000 - val_mae: 44383.9727\n",
            "Epoch 40/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4146012160.0000 - mae: 45433.4219 - val_loss: 4013255424.0000 - val_mae: 44828.6680\n",
            "Epoch 41/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4145313536.0000 - mae: 45308.7070 - val_loss: 3987775744.0000 - val_mae: 44604.7188\n",
            "Epoch 42/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4135464448.0000 - mae: 45352.9844 - val_loss: 3992652544.0000 - val_mae: 44685.1680\n",
            "Epoch 43/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4128892672.0000 - mae: 45189.1836 - val_loss: 4099897344.0000 - val_mae: 45311.4102\n",
            "Epoch 44/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4127139840.0000 - mae: 45244.6445 - val_loss: 4056951808.0000 - val_mae: 45488.2266\n",
            "Epoch 45/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4125147904.0000 - mae: 45248.1094 - val_loss: 3997746432.0000 - val_mae: 44850.9102\n",
            "Epoch 46/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4119639552.0000 - mae: 45202.4727 - val_loss: 3959512320.0000 - val_mae: 44488.5117\n",
            "Epoch 47/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4114606080.0000 - mae: 45135.0430 - val_loss: 3943977728.0000 - val_mae: 44062.0078\n",
            "Epoch 48/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4110488576.0000 - mae: 45075.3516 - val_loss: 3961395968.0000 - val_mae: 44213.1602\n",
            "Epoch 49/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4105701632.0000 - mae: 45080.6445 - val_loss: 3972949504.0000 - val_mae: 44300.9609\n",
            "Epoch 50/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4092702464.0000 - mae: 44936.8086 - val_loss: 3988597760.0000 - val_mae: 45078.2617\n",
            "Epoch 51/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4091522048.0000 - mae: 44965.5547 - val_loss: 4011577344.0000 - val_mae: 44523.6406\n",
            "Epoch 52/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4095574528.0000 - mae: 45000.2500 - val_loss: 3973466624.0000 - val_mae: 44359.9688\n",
            "Epoch 53/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4088984576.0000 - mae: 44914.4609 - val_loss: 4007431936.0000 - val_mae: 44486.8828\n",
            "Epoch 54/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4078045440.0000 - mae: 44814.2422 - val_loss: 3962776576.0000 - val_mae: 44354.7891\n",
            "Epoch 55/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4069926400.0000 - mae: 44847.7852 - val_loss: 3909352960.0000 - val_mae: 43567.4492\n",
            "Epoch 56/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4064554752.0000 - mae: 44740.0312 - val_loss: 3906476544.0000 - val_mae: 43972.9414\n",
            "Epoch 57/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4064296960.0000 - mae: 44786.7070 - val_loss: 3976928000.0000 - val_mae: 44452.2031\n",
            "Epoch 58/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4054257152.0000 - mae: 44642.4844 - val_loss: 3972219904.0000 - val_mae: 44293.6992\n",
            "Epoch 59/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4045758208.0000 - mae: 44657.6719 - val_loss: 3953928448.0000 - val_mae: 44414.6328\n",
            "Epoch 60/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4046934272.0000 - mae: 44596.4180 - val_loss: 3933813760.0000 - val_mae: 44103.5859\n",
            "Epoch 61/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4036860416.0000 - mae: 44581.4336 - val_loss: 3904975616.0000 - val_mae: 43714.5312\n",
            "Epoch 62/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4026480896.0000 - mae: 44462.7461 - val_loss: 3953895936.0000 - val_mae: 44359.7773\n",
            "Epoch 63/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4029355776.0000 - mae: 44538.3984 - val_loss: 3878064384.0000 - val_mae: 43640.7500\n",
            "Epoch 64/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4019304960.0000 - mae: 44445.9141 - val_loss: 3887623168.0000 - val_mae: 43624.4766\n",
            "Epoch 65/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 4005936128.0000 - mae: 44369.7656 - val_loss: 3829208064.0000 - val_mae: 43638.4844\n",
            "Epoch 66/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3989372928.0000 - mae: 44352.6797 - val_loss: 3840645632.0000 - val_mae: 43630.0781\n",
            "Epoch 67/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3984303360.0000 - mae: 44203.1562 - val_loss: 3855253504.0000 - val_mae: 43637.5039\n",
            "Epoch 68/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3979657984.0000 - mae: 44266.3008 - val_loss: 3800603392.0000 - val_mae: 43139.3438\n",
            "Epoch 69/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3963681024.0000 - mae: 44154.6562 - val_loss: 3755587840.0000 - val_mae: 42857.9648\n",
            "Epoch 70/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3959349760.0000 - mae: 44034.8984 - val_loss: 3738953984.0000 - val_mae: 43060.9336\n",
            "Epoch 71/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3938714880.0000 - mae: 44017.5273 - val_loss: 3785075200.0000 - val_mae: 43090.0664\n",
            "Epoch 72/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3930337280.0000 - mae: 43935.7070 - val_loss: 3793830912.0000 - val_mae: 43294.4336\n",
            "Epoch 73/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3917753344.0000 - mae: 43896.8242 - val_loss: 3780747264.0000 - val_mae: 43433.2930\n",
            "Epoch 74/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3906338304.0000 - mae: 43847.6484 - val_loss: 3704531200.0000 - val_mae: 42761.1445\n",
            "Epoch 75/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3905127680.0000 - mae: 43860.7227 - val_loss: 3790894848.0000 - val_mae: 43886.3867\n",
            "Epoch 76/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3894719232.0000 - mae: 43784.9531 - val_loss: 3684615936.0000 - val_mae: 42674.4805\n",
            "Epoch 77/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3884633856.0000 - mae: 43691.5703 - val_loss: 3651524864.0000 - val_mae: 42594.4102\n",
            "Epoch 78/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3867700224.0000 - mae: 43534.5586 - val_loss: 3660767744.0000 - val_mae: 42836.8438\n",
            "Epoch 79/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3862909184.0000 - mae: 43684.5273 - val_loss: 3619941120.0000 - val_mae: 42464.6172\n",
            "Epoch 80/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3849151744.0000 - mae: 43530.0703 - val_loss: 3678894080.0000 - val_mae: 43092.4023\n",
            "Epoch 81/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3845921536.0000 - mae: 43497.3438 - val_loss: 3602164992.0000 - val_mae: 42392.2852\n",
            "Epoch 82/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3846398720.0000 - mae: 43519.4609 - val_loss: 3647550720.0000 - val_mae: 43089.6602\n",
            "Epoch 83/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3834563584.0000 - mae: 43527.0078 - val_loss: 3659277824.0000 - val_mae: 42666.5234\n",
            "Epoch 84/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3827629056.0000 - mae: 43428.4688 - val_loss: 3589876224.0000 - val_mae: 42374.3984\n",
            "Epoch 85/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3818270208.0000 - mae: 43345.5938 - val_loss: 3697566464.0000 - val_mae: 43568.9766\n",
            "Epoch 86/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3809476352.0000 - mae: 43346.1875 - val_loss: 3568485632.0000 - val_mae: 42476.2070\n",
            "Epoch 87/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3802282496.0000 - mae: 43292.8164 - val_loss: 3617593856.0000 - val_mae: 42945.9570\n",
            "Epoch 88/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3800613376.0000 - mae: 43311.3398 - val_loss: 3580989184.0000 - val_mae: 42528.6094\n",
            "Epoch 89/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3792434944.0000 - mae: 43263.2969 - val_loss: 3609602560.0000 - val_mae: 42553.1836\n",
            "Epoch 90/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3800784128.0000 - mae: 43315.5469 - val_loss: 3556182272.0000 - val_mae: 42166.4609\n",
            "Epoch 91/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3783462656.0000 - mae: 43169.2070 - val_loss: 3613541632.0000 - val_mae: 42763.6797\n",
            "Epoch 92/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3773854720.0000 - mae: 43159.8555 - val_loss: 3584981504.0000 - val_mae: 42563.7422\n",
            "Epoch 93/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3776863232.0000 - mae: 43097.9805 - val_loss: 3617713920.0000 - val_mae: 43072.4062\n",
            "Epoch 94/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3777848320.0000 - mae: 43183.9609 - val_loss: 3537797888.0000 - val_mae: 42362.1953\n",
            "Epoch 95/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3762932480.0000 - mae: 43080.0586 - val_loss: 3544303360.0000 - val_mae: 42461.7812\n",
            "Epoch 96/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3754363904.0000 - mae: 43038.0664 - val_loss: 3557917440.0000 - val_mae: 42516.1523\n",
            "Epoch 97/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3755938816.0000 - mae: 42974.2188 - val_loss: 3523570688.0000 - val_mae: 42049.6523\n",
            "Epoch 98/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3748144384.0000 - mae: 42977.4805 - val_loss: 3540272384.0000 - val_mae: 42305.5977\n",
            "Epoch 99/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3735317248.0000 - mae: 42897.7656 - val_loss: 3521368064.0000 - val_mae: 42357.8047\n",
            "Epoch 100/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3741474048.0000 - mae: 42946.9688 - val_loss: 3562131456.0000 - val_mae: 42973.5742\n",
            "Epoch 101/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3732025344.0000 - mae: 42943.3125 - val_loss: 3488638464.0000 - val_mae: 41784.0742\n",
            "Epoch 102/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3727057408.0000 - mae: 42857.3477 - val_loss: 3514911488.0000 - val_mae: 42488.0820\n",
            "Epoch 103/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3717628672.0000 - mae: 42839.2148 - val_loss: 3511888896.0000 - val_mae: 41946.9805\n",
            "Epoch 104/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3710252800.0000 - mae: 42699.6641 - val_loss: 3474513664.0000 - val_mae: 42110.0742\n",
            "Epoch 105/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3709262848.0000 - mae: 42777.1758 - val_loss: 3503790848.0000 - val_mae: 42292.1719\n",
            "Epoch 106/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3702499840.0000 - mae: 42759.9922 - val_loss: 3454997760.0000 - val_mae: 41867.7695\n",
            "Epoch 107/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3694215936.0000 - mae: 42700.4609 - val_loss: 3450370048.0000 - val_mae: 41614.5195\n",
            "Epoch 108/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3691490304.0000 - mae: 42652.6562 - val_loss: 3474822912.0000 - val_mae: 41802.0195\n",
            "Epoch 109/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3681572352.0000 - mae: 42552.9531 - val_loss: 3467002112.0000 - val_mae: 42313.9883\n",
            "Epoch 110/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3674265600.0000 - mae: 42577.2656 - val_loss: 3522108160.0000 - val_mae: 42733.9180\n",
            "Epoch 111/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3675254528.0000 - mae: 42589.1328 - val_loss: 3416876544.0000 - val_mae: 41420.9961\n",
            "Epoch 112/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3660414208.0000 - mae: 42491.2383 - val_loss: 3498685696.0000 - val_mae: 42418.1875\n",
            "Epoch 113/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3650576896.0000 - mae: 42435.6719 - val_loss: 3438678272.0000 - val_mae: 41817.6016\n",
            "Epoch 114/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3656427008.0000 - mae: 42461.0781 - val_loss: 3463583488.0000 - val_mae: 42225.9766\n",
            "Epoch 115/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3640989696.0000 - mae: 42417.8008 - val_loss: 3438661632.0000 - val_mae: 41952.2109\n",
            "Epoch 116/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3636899840.0000 - mae: 42237.2773 - val_loss: 3406087168.0000 - val_mae: 41658.0000\n",
            "Epoch 117/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3626625280.0000 - mae: 42314.8125 - val_loss: 3440647424.0000 - val_mae: 42087.3125\n",
            "Epoch 118/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3623483648.0000 - mae: 42298.2891 - val_loss: 3397253632.0000 - val_mae: 41789.0430\n",
            "Epoch 119/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3613374976.0000 - mae: 42252.4102 - val_loss: 3370694912.0000 - val_mae: 41210.2969\n",
            "Epoch 120/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3606275328.0000 - mae: 42111.2969 - val_loss: 3406934528.0000 - val_mae: 42115.8086\n",
            "Epoch 121/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3590510336.0000 - mae: 42210.0000 - val_loss: 3374799360.0000 - val_mae: 41494.9219\n",
            "Epoch 122/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3583232000.0000 - mae: 42076.5430 - val_loss: 3349880832.0000 - val_mae: 40988.4805\n",
            "Epoch 123/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3581472000.0000 - mae: 41994.9531 - val_loss: 3428954624.0000 - val_mae: 42182.8438\n",
            "Epoch 124/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3575230464.0000 - mae: 42004.1562 - val_loss: 3360754688.0000 - val_mae: 41302.5508\n",
            "Epoch 125/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3570304000.0000 - mae: 41989.4141 - val_loss: 3338082816.0000 - val_mae: 41052.1875\n",
            "Epoch 126/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3561845760.0000 - mae: 41885.3633 - val_loss: 3365829376.0000 - val_mae: 41620.2656\n",
            "Epoch 127/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3554999808.0000 - mae: 41834.5586 - val_loss: 3462737152.0000 - val_mae: 42628.0625\n",
            "Epoch 128/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3546423808.0000 - mae: 41890.6445 - val_loss: 3378578176.0000 - val_mae: 41701.1484\n",
            "Epoch 129/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3542294528.0000 - mae: 41756.0156 - val_loss: 3339254272.0000 - val_mae: 41374.9258\n",
            "Epoch 130/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3533253120.0000 - mae: 41715.5938 - val_loss: 3325859840.0000 - val_mae: 41292.0508\n",
            "Epoch 131/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3527691264.0000 - mae: 41705.7617 - val_loss: 3289269504.0000 - val_mae: 40880.1836\n",
            "Epoch 132/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3522980608.0000 - mae: 41713.2773 - val_loss: 3429263360.0000 - val_mae: 42313.8086\n",
            "Epoch 133/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3518260224.0000 - mae: 41645.9336 - val_loss: 3296211456.0000 - val_mae: 41040.6172\n",
            "Epoch 134/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3503349248.0000 - mae: 41497.0781 - val_loss: 3277831936.0000 - val_mae: 41057.7852\n",
            "Epoch 135/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3496947456.0000 - mae: 41521.9688 - val_loss: 3302808064.0000 - val_mae: 41137.4492\n",
            "Epoch 136/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3496171264.0000 - mae: 41440.8945 - val_loss: 3250525440.0000 - val_mae: 40803.6523\n",
            "Epoch 137/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3486341120.0000 - mae: 41385.9062 - val_loss: 3319627264.0000 - val_mae: 41613.9805\n",
            "Epoch 138/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3474917376.0000 - mae: 41402.5742 - val_loss: 3280850944.0000 - val_mae: 41085.0195\n",
            "Epoch 139/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3472337152.0000 - mae: 41382.8750 - val_loss: 3222730752.0000 - val_mae: 40432.6406\n",
            "Epoch 140/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3465179136.0000 - mae: 41220.1797 - val_loss: 3234945536.0000 - val_mae: 40851.8164\n",
            "Epoch 141/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3459444480.0000 - mae: 41285.6250 - val_loss: 3308656384.0000 - val_mae: 41264.1758\n",
            "Epoch 142/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3452992000.0000 - mae: 41213.3398 - val_loss: 3308832000.0000 - val_mae: 41347.8906\n",
            "Epoch 143/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3448240128.0000 - mae: 41139.0078 - val_loss: 3238364672.0000 - val_mae: 40853.8125\n",
            "Epoch 144/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3444135936.0000 - mae: 41111.7930 - val_loss: 3227195392.0000 - val_mae: 40564.5781\n",
            "Epoch 145/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3439099648.0000 - mae: 41174.8867 - val_loss: 3266145280.0000 - val_mae: 40996.1484\n",
            "Epoch 146/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3428035072.0000 - mae: 40979.3711 - val_loss: 3222459392.0000 - val_mae: 40528.4648\n",
            "Epoch 147/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3422565888.0000 - mae: 41006.9375 - val_loss: 3200265216.0000 - val_mae: 40366.7617\n",
            "Epoch 148/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3417462272.0000 - mae: 41010.3281 - val_loss: 3239363584.0000 - val_mae: 40562.8633\n",
            "Epoch 149/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3415824384.0000 - mae: 40953.0508 - val_loss: 3200120064.0000 - val_mae: 40364.0352\n",
            "Epoch 150/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3408732416.0000 - mae: 40901.5117 - val_loss: 3216542720.0000 - val_mae: 40545.6602\n",
            "Epoch 151/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3392121856.0000 - mae: 40798.3359 - val_loss: 3159824128.0000 - val_mae: 39967.3867\n",
            "Epoch 152/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3390222592.0000 - mae: 40830.6289 - val_loss: 3245480448.0000 - val_mae: 40814.7188\n",
            "Epoch 153/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3392342784.0000 - mae: 40837.5898 - val_loss: 3205289728.0000 - val_mae: 40112.6250\n",
            "Epoch 154/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3384155904.0000 - mae: 40707.2617 - val_loss: 3205078016.0000 - val_mae: 40484.0508\n",
            "Epoch 155/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3381492992.0000 - mae: 40762.3281 - val_loss: 3197317120.0000 - val_mae: 40366.8086\n",
            "Epoch 156/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3375674624.0000 - mae: 40712.7852 - val_loss: 3169822720.0000 - val_mae: 40004.3203\n",
            "Epoch 157/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3374108160.0000 - mae: 40651.2578 - val_loss: 3199396096.0000 - val_mae: 40298.3984\n",
            "Epoch 158/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3361639168.0000 - mae: 40568.6992 - val_loss: 3170796032.0000 - val_mae: 40282.1133\n",
            "Epoch 159/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3360761344.0000 - mae: 40582.2812 - val_loss: 3187119872.0000 - val_mae: 40278.9570\n",
            "Epoch 160/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3363188736.0000 - mae: 40607.3477 - val_loss: 3135402496.0000 - val_mae: 39662.9570\n",
            "Epoch 161/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3355238912.0000 - mae: 40573.4141 - val_loss: 3165768960.0000 - val_mae: 40015.4531\n",
            "Epoch 162/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3349980672.0000 - mae: 40489.1797 - val_loss: 3139133184.0000 - val_mae: 39823.1250\n",
            "Epoch 163/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3351685120.0000 - mae: 40506.1406 - val_loss: 3191269376.0000 - val_mae: 40478.8047\n",
            "Epoch 164/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3344180480.0000 - mae: 40464.3320 - val_loss: 3143660800.0000 - val_mae: 39769.5469\n",
            "Epoch 165/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3332843520.0000 - mae: 40394.0547 - val_loss: 3139380736.0000 - val_mae: 39715.8086\n",
            "Epoch 166/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3332273152.0000 - mae: 40336.7539 - val_loss: 3193536768.0000 - val_mae: 40423.2188\n",
            "Epoch 167/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3330954240.0000 - mae: 40359.9492 - val_loss: 3111034880.0000 - val_mae: 39376.0352\n",
            "Epoch 168/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3322044928.0000 - mae: 40297.7617 - val_loss: 3133120768.0000 - val_mae: 39746.9375\n",
            "Epoch 169/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3320503296.0000 - mae: 40260.6406 - val_loss: 3136515328.0000 - val_mae: 40067.9219\n",
            "Epoch 170/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3317253120.0000 - mae: 40288.7070 - val_loss: 3174303232.0000 - val_mae: 40148.4102\n",
            "Epoch 171/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3310540288.0000 - mae: 40197.3867 - val_loss: 3141231360.0000 - val_mae: 40007.2617\n",
            "Epoch 172/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3312752384.0000 - mae: 40265.1289 - val_loss: 3171134208.0000 - val_mae: 40064.0859\n",
            "Epoch 173/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3300795648.0000 - mae: 40113.5391 - val_loss: 3091438592.0000 - val_mae: 39458.7812\n",
            "Epoch 174/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3303805952.0000 - mae: 40188.9336 - val_loss: 3130010880.0000 - val_mae: 39553.4492\n",
            "Epoch 175/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3294658816.0000 - mae: 40086.2422 - val_loss: 3129481728.0000 - val_mae: 39715.0430\n",
            "Epoch 176/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3288724992.0000 - mae: 40022.7656 - val_loss: 3094580736.0000 - val_mae: 39252.9102\n",
            "Epoch 177/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3288473856.0000 - mae: 40044.1680 - val_loss: 3088765440.0000 - val_mae: 39069.1953\n",
            "Epoch 178/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3281338368.0000 - mae: 39974.2266 - val_loss: 3108968448.0000 - val_mae: 39501.0078\n",
            "Epoch 179/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3284805888.0000 - mae: 40012.6523 - val_loss: 3071163136.0000 - val_mae: 39043.4648\n",
            "Epoch 180/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3278904064.0000 - mae: 39895.1016 - val_loss: 3154994176.0000 - val_mae: 40234.4102\n",
            "Epoch 181/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3269147136.0000 - mae: 39956.0938 - val_loss: 3096548608.0000 - val_mae: 39434.3359\n",
            "Epoch 182/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3276857344.0000 - mae: 39943.1875 - val_loss: 3065390592.0000 - val_mae: 39170.2891\n",
            "Epoch 183/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3267627264.0000 - mae: 39862.9297 - val_loss: 3121441024.0000 - val_mae: 39698.1484\n",
            "Epoch 184/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3266536704.0000 - mae: 39874.6797 - val_loss: 3063720704.0000 - val_mae: 39171.6797\n",
            "Epoch 185/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3258358528.0000 - mae: 39874.1133 - val_loss: 3084689664.0000 - val_mae: 39095.9922\n",
            "Epoch 186/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3257504512.0000 - mae: 39784.1953 - val_loss: 3077825792.0000 - val_mae: 39069.8945\n",
            "Epoch 187/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3262962944.0000 - mae: 39824.8516 - val_loss: 3071169536.0000 - val_mae: 39431.1602\n",
            "Epoch 188/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3253220352.0000 - mae: 39828.8828 - val_loss: 3108940032.0000 - val_mae: 39607.7188\n",
            "Epoch 189/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3245667840.0000 - mae: 39695.3125 - val_loss: 3073300736.0000 - val_mae: 39267.6953\n",
            "Epoch 190/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3242070528.0000 - mae: 39701.6562 - val_loss: 3060566016.0000 - val_mae: 39059.7812\n",
            "Epoch 191/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3248568064.0000 - mae: 39728.2188 - val_loss: 3131400448.0000 - val_mae: 39801.2422\n",
            "Epoch 192/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3240800512.0000 - mae: 39713.7852 - val_loss: 3127788032.0000 - val_mae: 39751.5312\n",
            "Epoch 193/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3242325504.0000 - mae: 39701.1680 - val_loss: 3096569856.0000 - val_mae: 39666.9453\n",
            "Epoch 194/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3237193216.0000 - mae: 39664.2148 - val_loss: 3118522368.0000 - val_mae: 39901.7773\n",
            "Epoch 195/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3238106112.0000 - mae: 39664.7070 - val_loss: 3035099904.0000 - val_mae: 39061.0938\n",
            "Epoch 196/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3220891392.0000 - mae: 39583.5820 - val_loss: 3068836608.0000 - val_mae: 39406.6836\n",
            "Epoch 197/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3224341760.0000 - mae: 39557.7109 - val_loss: 3019785472.0000 - val_mae: 38692.8125\n",
            "Epoch 198/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3225381632.0000 - mae: 39598.2656 - val_loss: 3085580288.0000 - val_mae: 39414.7812\n",
            "Epoch 199/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3221232640.0000 - mae: 39528.4766 - val_loss: 3029109760.0000 - val_mae: 38959.9453\n",
            "Epoch 200/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3215710208.0000 - mae: 39510.3125 - val_loss: 3122087936.0000 - val_mae: 39832.8984\n",
            "Epoch 201/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3214864384.0000 - mae: 39572.6680 - val_loss: 3005708032.0000 - val_mae: 38641.1875\n",
            "Epoch 202/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3209468672.0000 - mae: 39398.5430 - val_loss: 3038707712.0000 - val_mae: 39082.8984\n",
            "Epoch 203/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3206064640.0000 - mae: 39480.2383 - val_loss: 3057428224.0000 - val_mae: 39223.0312\n",
            "Epoch 204/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3203101440.0000 - mae: 39369.7344 - val_loss: 3165199360.0000 - val_mae: 40472.0352\n",
            "Epoch 205/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3199011072.0000 - mae: 39437.2656 - val_loss: 3087780608.0000 - val_mae: 39262.7148\n",
            "Epoch 206/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3195645952.0000 - mae: 39290.4141 - val_loss: 3008370944.0000 - val_mae: 38920.6992\n",
            "Epoch 207/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3198457344.0000 - mae: 39343.6719 - val_loss: 3004639232.0000 - val_mae: 38713.8281\n",
            "Epoch 208/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3183665664.0000 - mae: 39248.1992 - val_loss: 3015983616.0000 - val_mae: 38728.0000\n",
            "Epoch 209/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3192957696.0000 - mae: 39372.8242 - val_loss: 3097245696.0000 - val_mae: 39586.7422\n",
            "Epoch 210/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3179976448.0000 - mae: 39201.9805 - val_loss: 3033906944.0000 - val_mae: 39209.1680\n",
            "Epoch 211/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3179764992.0000 - mae: 39221.4258 - val_loss: 3061767424.0000 - val_mae: 39277.3633\n",
            "Epoch 212/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3173778432.0000 - mae: 39148.0430 - val_loss: 3008879360.0000 - val_mae: 38667.3750\n",
            "Epoch 213/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3173494272.0000 - mae: 39204.2773 - val_loss: 3013226240.0000 - val_mae: 38844.3398\n",
            "Epoch 214/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3167867904.0000 - mae: 39186.4062 - val_loss: 2980098048.0000 - val_mae: 38450.1641\n",
            "Epoch 215/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3157950720.0000 - mae: 39056.7344 - val_loss: 3016830464.0000 - val_mae: 38954.5273\n",
            "Epoch 216/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3150011648.0000 - mae: 39023.1211 - val_loss: 2996950528.0000 - val_mae: 38761.4492\n",
            "Epoch 217/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3163299584.0000 - mae: 39161.3906 - val_loss: 2995165440.0000 - val_mae: 38705.4922\n",
            "Epoch 218/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3148626432.0000 - mae: 39059.4883 - val_loss: 2968625408.0000 - val_mae: 38225.3320\n",
            "Epoch 219/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3144682240.0000 - mae: 39004.9727 - val_loss: 2974559232.0000 - val_mae: 38323.4062\n",
            "Epoch 220/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3148600320.0000 - mae: 38973.5391 - val_loss: 3012553728.0000 - val_mae: 38973.0312\n",
            "Epoch 221/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3146982144.0000 - mae: 38998.3516 - val_loss: 2958974208.0000 - val_mae: 38284.3203\n",
            "Epoch 222/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3134167040.0000 - mae: 38885.4180 - val_loss: 2953320704.0000 - val_mae: 38156.7852\n",
            "Epoch 223/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3132371712.0000 - mae: 38884.6680 - val_loss: 2969538048.0000 - val_mae: 38473.5703\n",
            "Epoch 224/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3137147392.0000 - mae: 38906.7109 - val_loss: 2969819904.0000 - val_mae: 38728.5625\n",
            "Epoch 225/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3127682560.0000 - mae: 38835.9727 - val_loss: 3093652992.0000 - val_mae: 39842.7070\n",
            "Epoch 226/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3135300864.0000 - mae: 38912.8359 - val_loss: 2941232640.0000 - val_mae: 38319.3945\n",
            "Epoch 227/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3118680576.0000 - mae: 38750.4922 - val_loss: 3010906112.0000 - val_mae: 38898.7344\n",
            "Epoch 228/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3120349696.0000 - mae: 38795.3242 - val_loss: 2951788800.0000 - val_mae: 38546.4766\n",
            "Epoch 229/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3120372736.0000 - mae: 38847.1836 - val_loss: 2964776960.0000 - val_mae: 38525.6602\n",
            "Epoch 230/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3112284160.0000 - mae: 38724.2070 - val_loss: 2942016768.0000 - val_mae: 38309.4531\n",
            "Epoch 231/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3102484224.0000 - mae: 38683.6875 - val_loss: 2950766080.0000 - val_mae: 38377.8711\n",
            "Epoch 232/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3107454208.0000 - mae: 38666.6719 - val_loss: 3015349248.0000 - val_mae: 39073.3594\n",
            "Epoch 233/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3107465472.0000 - mae: 38654.6250 - val_loss: 2935326464.0000 - val_mae: 38053.7930\n",
            "Epoch 234/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3101535232.0000 - mae: 38695.6641 - val_loss: 2954426624.0000 - val_mae: 38590.9570\n",
            "Epoch 235/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3104798976.0000 - mae: 38616.4688 - val_loss: 2912389632.0000 - val_mae: 38123.1016\n",
            "Epoch 236/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3101681408.0000 - mae: 38614.2070 - val_loss: 3000123904.0000 - val_mae: 38853.0078\n",
            "Epoch 237/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3090439936.0000 - mae: 38555.5078 - val_loss: 2937920768.0000 - val_mae: 38327.6172\n",
            "Epoch 238/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3085932800.0000 - mae: 38545.1484 - val_loss: 2972433152.0000 - val_mae: 38669.0469\n",
            "Epoch 239/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3086234112.0000 - mae: 38504.7305 - val_loss: 2931605248.0000 - val_mae: 38292.5156\n",
            "Epoch 240/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3079665920.0000 - mae: 38467.3711 - val_loss: 3010371072.0000 - val_mae: 38749.7266\n",
            "Epoch 241/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3082183168.0000 - mae: 38503.0625 - val_loss: 2948401664.0000 - val_mae: 38253.7383\n",
            "Epoch 242/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3076822528.0000 - mae: 38410.0039 - val_loss: 2965091584.0000 - val_mae: 38739.9492\n",
            "Epoch 243/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3071558400.0000 - mae: 38502.5820 - val_loss: 2933282304.0000 - val_mae: 38086.1406\n",
            "Epoch 244/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3071770880.0000 - mae: 38407.5781 - val_loss: 2895105536.0000 - val_mae: 38051.1133\n",
            "Epoch 245/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3070273792.0000 - mae: 38393.1172 - val_loss: 2912718080.0000 - val_mae: 37819.9961\n",
            "Epoch 246/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3060911872.0000 - mae: 38351.9609 - val_loss: 2974808064.0000 - val_mae: 38611.8516\n",
            "Epoch 247/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3062403840.0000 - mae: 38349.1289 - val_loss: 2993211648.0000 - val_mae: 38764.1836\n",
            "Epoch 248/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3059562752.0000 - mae: 38355.1250 - val_loss: 2943563008.0000 - val_mae: 38301.6445\n",
            "Epoch 249/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3055900672.0000 - mae: 38301.3320 - val_loss: 2920604416.0000 - val_mae: 38152.9805\n",
            "Epoch 250/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3056000768.0000 - mae: 38309.8281 - val_loss: 2959791104.0000 - val_mae: 38508.6484\n",
            "Epoch 251/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3049848832.0000 - mae: 38210.9023 - val_loss: 3035630848.0000 - val_mae: 39614.0820\n",
            "Epoch 252/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3044776448.0000 - mae: 38308.1133 - val_loss: 2903876608.0000 - val_mae: 38139.7695\n",
            "Epoch 253/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3043949568.0000 - mae: 38325.1133 - val_loss: 2937496320.0000 - val_mae: 38623.9219\n",
            "Epoch 254/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3039260160.0000 - mae: 38218.2695 - val_loss: 2879088896.0000 - val_mae: 37682.1484\n",
            "Epoch 255/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3030011904.0000 - mae: 38106.9141 - val_loss: 2936974592.0000 - val_mae: 38278.9805\n",
            "Epoch 256/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3035746816.0000 - mae: 38191.8555 - val_loss: 2927396352.0000 - val_mae: 38154.5273\n",
            "Epoch 257/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 3027388416.0000 - mae: 38140.3672 - val_loss: 2949354496.0000 - val_mae: 38571.2305\n",
            "Epoch 258/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3022158336.0000 - mae: 38080.4062 - val_loss: 2959940608.0000 - val_mae: 38222.1562\n",
            "Epoch 259/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3026952448.0000 - mae: 38074.7461 - val_loss: 3023816448.0000 - val_mae: 39291.4492\n",
            "Epoch 260/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3023906048.0000 - mae: 38138.2227 - val_loss: 3072910336.0000 - val_mae: 40186.1719\n",
            "Epoch 261/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3012942336.0000 - mae: 38037.4219 - val_loss: 3045761024.0000 - val_mae: 39388.8242\n",
            "Epoch 262/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3019171072.0000 - mae: 38074.2578 - val_loss: 2875284480.0000 - val_mae: 37475.3633\n",
            "Epoch 263/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3019232000.0000 - mae: 38000.3086 - val_loss: 2996467200.0000 - val_mae: 39060.2812\n",
            "Epoch 264/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3013031680.0000 - mae: 38034.5820 - val_loss: 2955005184.0000 - val_mae: 38503.6758\n",
            "Epoch 265/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2999998464.0000 - mae: 37953.3711 - val_loss: 2872955136.0000 - val_mae: 37505.4062\n",
            "Epoch 266/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3005414144.0000 - mae: 37941.6328 - val_loss: 2952759296.0000 - val_mae: 38608.6250\n",
            "Epoch 267/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3000995328.0000 - mae: 37938.3281 - val_loss: 2885736960.0000 - val_mae: 37678.6953\n",
            "Epoch 268/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 3005336576.0000 - mae: 37993.3633 - val_loss: 2892576512.0000 - val_mae: 37702.5898\n",
            "Epoch 269/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2989859840.0000 - mae: 37917.5312 - val_loss: 2882979072.0000 - val_mae: 37880.0156\n",
            "Epoch 270/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2992290816.0000 - mae: 37912.9297 - val_loss: 2873606656.0000 - val_mae: 37612.1016\n",
            "Epoch 271/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2993844224.0000 - mae: 37892.7227 - val_loss: 2895914752.0000 - val_mae: 37809.7695\n",
            "Epoch 272/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2985343744.0000 - mae: 37802.5117 - val_loss: 2884720384.0000 - val_mae: 37761.9062\n",
            "Epoch 273/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2984985344.0000 - mae: 37881.4023 - val_loss: 2899117056.0000 - val_mae: 37838.9688\n",
            "Epoch 274/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2981914624.0000 - mae: 37788.9922 - val_loss: 2938202368.0000 - val_mae: 38274.0234\n",
            "Epoch 275/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2978483456.0000 - mae: 37830.4297 - val_loss: 2880036608.0000 - val_mae: 37623.6367\n",
            "Epoch 276/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2974933760.0000 - mae: 37752.7773 - val_loss: 2859826688.0000 - val_mae: 37626.2188\n",
            "Epoch 277/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2973961216.0000 - mae: 37711.6367 - val_loss: 2903191296.0000 - val_mae: 38083.8516\n",
            "Epoch 278/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2968014336.0000 - mae: 37751.2422 - val_loss: 2838533888.0000 - val_mae: 37287.6836\n",
            "Epoch 279/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2971660288.0000 - mae: 37721.4023 - val_loss: 2842516736.0000 - val_mae: 37081.6992\n",
            "Epoch 280/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2967030784.0000 - mae: 37704.6641 - val_loss: 2848529920.0000 - val_mae: 37147.9844\n",
            "Epoch 281/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2966931968.0000 - mae: 37741.6562 - val_loss: 2877504256.0000 - val_mae: 37862.8281\n",
            "Epoch 282/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2960980480.0000 - mae: 37677.5859 - val_loss: 2867677184.0000 - val_mae: 37622.5508\n",
            "Epoch 283/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2956633088.0000 - mae: 37733.0703 - val_loss: 2835935744.0000 - val_mae: 36922.1758\n",
            "Epoch 284/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2958234368.0000 - mae: 37648.0586 - val_loss: 2895581952.0000 - val_mae: 37566.8164\n",
            "Epoch 285/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2952703744.0000 - mae: 37573.9219 - val_loss: 2845030656.0000 - val_mae: 37414.8047\n",
            "Epoch 286/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2948312576.0000 - mae: 37650.7930 - val_loss: 2851831296.0000 - val_mae: 37627.6445\n",
            "Epoch 287/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2948901120.0000 - mae: 37562.6523 - val_loss: 2858329856.0000 - val_mae: 37681.6836\n",
            "Epoch 288/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2944569088.0000 - mae: 37565.7578 - val_loss: 2910233344.0000 - val_mae: 38011.8867\n",
            "Epoch 289/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2939541760.0000 - mae: 37471.3633 - val_loss: 2863385344.0000 - val_mae: 37871.3672\n",
            "Epoch 290/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2944474112.0000 - mae: 37535.3125 - val_loss: 2844056832.0000 - val_mae: 37310.5156\n",
            "Epoch 291/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2932947200.0000 - mae: 37543.7109 - val_loss: 2870503680.0000 - val_mae: 36999.1484\n",
            "Epoch 292/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2940814080.0000 - mae: 37527.2969 - val_loss: 2887702784.0000 - val_mae: 37543.8516\n",
            "Epoch 293/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2932751616.0000 - mae: 37472.3516 - val_loss: 2836517376.0000 - val_mae: 37706.0234\n",
            "Epoch 294/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2937994240.0000 - mae: 37575.8242 - val_loss: 2870991616.0000 - val_mae: 37827.3906\n",
            "Epoch 295/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2932896512.0000 - mae: 37485.6484 - val_loss: 2828845824.0000 - val_mae: 37098.6953\n",
            "Epoch 296/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2930458880.0000 - mae: 37491.2461 - val_loss: 2889804800.0000 - val_mae: 37841.8242\n",
            "Epoch 297/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2923054336.0000 - mae: 37446.6445 - val_loss: 2825756416.0000 - val_mae: 37487.9297\n",
            "Epoch 298/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2919021056.0000 - mae: 37442.6836 - val_loss: 2881168640.0000 - val_mae: 37953.7109\n",
            "Epoch 299/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2911207168.0000 - mae: 37295.9883 - val_loss: 2841914368.0000 - val_mae: 37607.6250\n",
            "Epoch 300/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2913153536.0000 - mae: 37347.9102 - val_loss: 2861064448.0000 - val_mae: 37807.3438\n",
            "Epoch 301/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2911724288.0000 - mae: 37350.8672 - val_loss: 2821810432.0000 - val_mae: 36983.4062\n",
            "Epoch 302/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2912472576.0000 - mae: 37323.5078 - val_loss: 2879241984.0000 - val_mae: 37410.2070\n",
            "Epoch 303/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2912900864.0000 - mae: 37410.5508 - val_loss: 2792283136.0000 - val_mae: 36581.6484\n",
            "Epoch 304/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2908298240.0000 - mae: 37278.0039 - val_loss: 2782848256.0000 - val_mae: 36756.9375\n",
            "Epoch 305/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2903172864.0000 - mae: 37256.1875 - val_loss: 2923046400.0000 - val_mae: 37900.5898\n",
            "Epoch 306/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2908510720.0000 - mae: 37315.0000 - val_loss: 2826817792.0000 - val_mae: 37436.7148\n",
            "Epoch 307/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2890006784.0000 - mae: 37120.4375 - val_loss: 2810282240.0000 - val_mae: 36852.3398\n",
            "Epoch 308/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2894081536.0000 - mae: 37268.3242 - val_loss: 2814993664.0000 - val_mae: 36958.7656\n",
            "Epoch 309/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2887592960.0000 - mae: 37185.1250 - val_loss: 2885709568.0000 - val_mae: 37581.9336\n",
            "Epoch 310/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2894275328.0000 - mae: 37169.3555 - val_loss: 2818853632.0000 - val_mae: 37112.8516\n",
            "Epoch 311/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2883402752.0000 - mae: 37146.1758 - val_loss: 2801103360.0000 - val_mae: 36597.3477\n",
            "Epoch 312/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2888173056.0000 - mae: 37201.7969 - val_loss: 2867481344.0000 - val_mae: 37582.5820\n",
            "Epoch 313/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2886845952.0000 - mae: 37234.4492 - val_loss: 2907413760.0000 - val_mae: 38152.5508\n",
            "Epoch 314/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2882076928.0000 - mae: 37159.4219 - val_loss: 2848693248.0000 - val_mae: 37553.4883\n",
            "Epoch 315/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2882950144.0000 - mae: 37190.1875 - val_loss: 2843276288.0000 - val_mae: 37121.1406\n",
            "Epoch 316/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2875328256.0000 - mae: 37069.8711 - val_loss: 2798548480.0000 - val_mae: 37172.7109\n",
            "Epoch 317/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2876803584.0000 - mae: 37036.2031 - val_loss: 2767245056.0000 - val_mae: 36537.9297\n",
            "Epoch 318/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2878128640.0000 - mae: 37137.4414 - val_loss: 2820014848.0000 - val_mae: 37238.2578\n",
            "Epoch 319/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2868214016.0000 - mae: 37056.2188 - val_loss: 2884956928.0000 - val_mae: 38150.3750\n",
            "Epoch 320/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2869804800.0000 - mae: 37013.5859 - val_loss: 2990310656.0000 - val_mae: 38946.4297\n",
            "Epoch 321/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2865164032.0000 - mae: 37030.2539 - val_loss: 2816328960.0000 - val_mae: 37255.6406\n",
            "Epoch 322/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2864197120.0000 - mae: 37061.5039 - val_loss: 2812534784.0000 - val_mae: 37005.9805\n",
            "Epoch 323/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2861116672.0000 - mae: 36988.9961 - val_loss: 2777353728.0000 - val_mae: 36377.6758\n",
            "Epoch 324/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2863599360.0000 - mae: 36968.3125 - val_loss: 2790653696.0000 - val_mae: 36589.6055\n",
            "Epoch 325/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2861392128.0000 - mae: 36975.4648 - val_loss: 2790017792.0000 - val_mae: 36530.1406\n",
            "Epoch 326/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2848575232.0000 - mae: 36867.4883 - val_loss: 2742692352.0000 - val_mae: 36326.8672\n",
            "Epoch 327/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2854427392.0000 - mae: 36910.3047 - val_loss: 2790111232.0000 - val_mae: 36772.9688\n",
            "Epoch 328/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2841503488.0000 - mae: 36750.0430 - val_loss: 2819816448.0000 - val_mae: 37122.1250\n",
            "Epoch 329/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2852331776.0000 - mae: 36931.3281 - val_loss: 2870637824.0000 - val_mae: 37370.3398\n",
            "Epoch 330/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2847439872.0000 - mae: 36801.2031 - val_loss: 2748904960.0000 - val_mae: 36537.8867\n",
            "Epoch 331/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2847542528.0000 - mae: 36927.9453 - val_loss: 2834177024.0000 - val_mae: 37374.6055\n",
            "Epoch 332/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2854702592.0000 - mae: 36982.8672 - val_loss: 2775672576.0000 - val_mae: 36377.1016\n",
            "Epoch 333/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2844298752.0000 - mae: 36827.7617 - val_loss: 2800917760.0000 - val_mae: 37289.8242\n",
            "Epoch 334/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2850693120.0000 - mae: 36901.2422 - val_loss: 2951636480.0000 - val_mae: 38111.3281\n",
            "Epoch 335/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2829936128.0000 - mae: 36746.3359 - val_loss: 2862236160.0000 - val_mae: 37447.1680\n",
            "Epoch 336/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2843049472.0000 - mae: 36828.9766 - val_loss: 2890890752.0000 - val_mae: 37828.9492\n",
            "Epoch 337/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2840746496.0000 - mae: 36802.7188 - val_loss: 2778717440.0000 - val_mae: 36425.8398\n",
            "Epoch 338/350\n",
            "383/383 [==============================] - 1s 3ms/step - loss: 2831048192.0000 - mae: 36696.1367 - val_loss: 2746125056.0000 - val_mae: 36202.1836\n",
            "Epoch 339/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2831649280.0000 - mae: 36761.3555 - val_loss: 2733134080.0000 - val_mae: 36335.4141\n",
            "Epoch 340/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2825239552.0000 - mae: 36722.8789 - val_loss: 2779247872.0000 - val_mae: 36653.7695\n",
            "Epoch 341/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2827261440.0000 - mae: 36686.7500 - val_loss: 2754951936.0000 - val_mae: 36246.6055\n",
            "Epoch 342/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2817869312.0000 - mae: 36614.7148 - val_loss: 2743929600.0000 - val_mae: 36308.6914\n",
            "Epoch 343/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2819085056.0000 - mae: 36682.7266 - val_loss: 2864217600.0000 - val_mae: 37550.4492\n",
            "Epoch 344/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2823318016.0000 - mae: 36762.5234 - val_loss: 2753740800.0000 - val_mae: 36091.2031\n",
            "Epoch 345/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2819956224.0000 - mae: 36647.1914 - val_loss: 2783373824.0000 - val_mae: 36740.8594\n",
            "Epoch 346/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2815272704.0000 - mae: 36676.4766 - val_loss: 2778709504.0000 - val_mae: 36779.2812\n",
            "Epoch 347/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2805885696.0000 - mae: 36595.4922 - val_loss: 2767438848.0000 - val_mae: 36461.3047\n",
            "Epoch 348/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2806721024.0000 - mae: 36599.6328 - val_loss: 2713884160.0000 - val_mae: 35962.5156\n",
            "Epoch 349/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2812663552.0000 - mae: 36565.5781 - val_loss: 2731486976.0000 - val_mae: 36180.0508\n",
            "Epoch 350/350\n",
            "383/383 [==============================] - 1s 2ms/step - loss: 2807778560.0000 - mae: 36650.0000 - val_loss: 2745171968.0000 - val_mae: 35945.5430\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train, epochs=350, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxjvJyS3UWxw"
      },
      "source": [
        "---\n",
        "\n",
        "11.\tСохраните лучшую модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmTFOxG-UYqj"
      },
      "outputs": [],
      "source": [
        "model.save('model_lab_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN--27-7gX1Z"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('model_lab_3')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}